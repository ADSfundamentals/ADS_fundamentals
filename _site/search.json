[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ADS fundamentals",
    "section": "",
    "text": "Welcome to the course “Fundamental Techniques in Data Science with R”."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "manual.html",
    "href": "manual.html",
    "title": "Course manual",
    "section": "",
    "text": "Regression techniques are widely used to quantify the relationship between two or more variables. In data science, linear and logistic regression are common and powerful techniques for evaluating such relations. These techniques are only useful, however, once you understand when and how to apply them. In this course, students will learn how to apply linear and logistic regression with the R statistical software package.\nThis course will introduce students to the principles of analytical data science, linear and logistic regression, and the basics of statistical learning. Students will develop fundamental R programming skills and will gain experience with tidyverse: visualize data with ggplot2 and performing basic data wrangling with dplyr. This course helps prepare students for an entry-level research career (e.g. junior researcher or research assistant) or further education in research (e.g., a [research] Master program or a PhD)."
  },
  {
    "objectID": "preperation.html",
    "href": "preperation.html",
    "title": "Preparation",
    "section": "",
    "text": "In this course, you will use both R and RStudio.\nIf you have never worked with R before, use the tutorials from Open Statistical Programming to be ready and prepared before the course starts. The materials discussed in the tutorials\n\nSoftware setup\nFirst steps\nData types\nWorkflow\nBasic visualizations\n\nare required knowledge before you start the course!"
  },
  {
    "objectID": "index.html#important-links",
    "href": "index.html#important-links",
    "title": "ADS fundamentals",
    "section": "Important links",
    "text": "Important links\n\nCoordinator: [Laura Boeschoten]\nInstructors: [Kyle Lang], [Anastasia Giachanou], [Noor]\nRooms: See [MyTimetable]\nCourse manual:\nInstructions group assignments:\nLink to upload group assignments:\nExam information:\nLink to upload labs:"
  },
  {
    "objectID": "index.html#weekly-schedule",
    "href": "index.html#weekly-schedule",
    "title": "ADS fundamentals",
    "section": "Weekly schedule",
    "text": "Weekly schedule\n\n\n\nWeek\n1\nDate\n10-11 (Mon)\nContent\nLecture\nPrepare\n\nRead course manual\nCheck preparation\nRead R4DS Ch. 3, 4, 7, 13, 16\n\n\n\n\n\n\n\n\n\n\n\n1\n11-11 (Tue)\nQ&A - online\n\n\n\n\n1\n13-11 (Thu)\nWG\nBe present to pass the course!!\n\n\n\n2\n17-11 (Mon)\nDeadline lab 1: 15:00\n\nLab 1\n\n\n\n\n2\n17-11 (Mon)\nLecture\n\nRead R4DS Ch. 1, 9, 10\nRead SDAM Ch. 4\n\n\n\n\n2\n18-11 (Tue)\nQ&A - online\n\n\n\n\n2\n20-11 (Thu)\nWG\n\n\n\n\n3\n24-11 (Mon)\nDeadline lab 2: 15:00\n\nLab 2 (solutions)\n\n\n\n\n3\n24-11 (Mon)\nLecture\n\nRead SDAM Ch. 5.1 - 5.6, 6.1\n\n\n\n\n3\n25-11 (Tue)\nQ&A - online\n\n\n\n\n3\n27-11 (Thu)\nWG\n\n\n\n\n4\n1-12 (Mon)\nDeadline lab 3: 15:00\n\nLab 3 (solutions)\n\n\n\n\n4\n1-12 (Mon)\nLecture\n\nRead SDAM Ch. 5.7 - 5.9\nRead this and this\n\n\n\n\n4\n2-12 (Tue)\nQ&A - online\n\n\n\n\n4\n4-12 (Thu)\nWG\n\n\n\n\n5\n8-12 (Mon)\nDeadline lab 4: 15:00\n\nLab 4 (solutions)\n\n\n\n\n5\n8-12 (Mon)\nDeadline assignment 1: 15:00\n\n\n\n\n5\n8-12 (Mon)\nLecture\n\nRead SDAM Ch. 12.1 - 12.5, 12.8\nRead this\n\n\n\n\n5\n9-12 (Tue)\nQ&A - online\n\n\n\n\n5\n11-12 (Thu)\nWG\n\n\n\n\n6\n15-12 (Mon)\nDeadline lab 5: 15:00\n\nLab 5 (solutions)\n\n\n\n\n6\n15-12 (Mon)\nLecture\n\nRead this\nRead Book420 CH. 17.4\n\n\n\n\n6\n16-12 (Tue)\nQ&A - online\n\n\n\n\n6\n18-12 (Thu)\nWG\n\n\n\n\n7\n12-1 (Mon)\nDeadline lab 6: 15:00\n\nLab 6 (solutions)\n\n\n\n\n7\n12-1 (Mon)\nRecap and Q&A\n\n\n\n\n7\n15-1 (Thu)\nPresentations assignment 2\nBe present to pass the course!!\n\n\n\n8\n22-1 (Thu)\nExam"
  },
  {
    "objectID": "exam.html",
    "href": "exam.html",
    "title": "Exam",
    "section": "",
    "text": "Anything mentioned in the lectures may appear on the exam.\nThis includes both information printed in the lecture slides and information delivered verbally during a lecture itself.Anything covered in the required readings may appear on the exam.\nObviously, this is a lot of material. To prioritize, keep in mind that topics mentioned in the lectures and topics directly related to ideas covered in the lectures are most likely to appear on the exam.\nThe materials presented on the “preparation” page can also be part of the exam since this is required knowledge.\nSummary of the required readings:\n\nR4DS: Ch. 1, 3, 4, 7, 9, 10, 13, 16.\nSDAM: Ch. 1, 2, 3, 4, 5, 6.1, 12.1-12.5, 12.8.\nBook420: Ch.17.4.\nhttps://stats.oarc.ucla.edu/r/dae/robust-regression/\nhttps://stats.oarc.ucla.edu/r/dae/robust-regression/\nhttps://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/\nhttps://stats.oarc.ucla.edu/r/dae/logit-regression/"
  },
  {
    "objectID": "manual.html#course-structure",
    "href": "manual.html#course-structure",
    "title": "Course manual",
    "section": "Course structure",
    "text": "Course structure\nIn seven weeks, you will learn the basics of data handling and statistical programming with R and details about regression techniques in the context of statistical inference, prediction, and classification. Each week will comprise four activities:\n\nDuring the weekly in-person lectures, we will cover the theoretical content.\nDuring the weekly in-person workgroup meetings, you will work on real-world data analysis with a group of your peers.\nWeekly self-study practical exercises connect the statistical theory to practice by applying the lecture content in the R statistical programming language.\nThere is an online weekly Q&A session in case you get stuck or have questions."
  },
  {
    "objectID": "manual.html#how-to-pass-the-course",
    "href": "manual.html#how-to-pass-the-course",
    "title": "Course manual",
    "section": "How to pass the course",
    "text": "How to pass the course\nYour final grade consists of three elements:\n\n\n\nGrade component\nWeight\nRequired minimum grade\n\n\n\n\nGroup assignment 1\n25%\n5.5\n\n\nGroup assignment 2\n25%\n5.5\n\n\nWritten exam in Remindo\n50%\n5.5\n\n\n\n\nAttendance\nDuring this course, you will attend 7 lectures, 7 workgroup sessions and hand in 6 practical assignments.\nAttendance for the lectures and the workgroup sessions is mandatory. You work on your group assignments during the workgroup meetings. For a collaborative spirit, attendance is crucial.\n\n\nTesting procedure\nThere are two opportunities per year to take a test.\n\nShould circumstances prevent you from taking the first opportunity, you will be invited to the second. It is not necessary to deregister.\nIf you do not obtain a satisfactory final grade on the second opportunity, you will have to retake the course in the 2026-2027 academic year. See detailed information on testing on the student website.\nbut you have obtained a pass for one part (e.g. an assignment or the exam), then you do not have to redo this part next year."
  },
  {
    "objectID": "manual.html#course-objectives-and-learning-outcomes",
    "href": "manual.html#course-objectives-and-learning-outcomes",
    "title": "Course manual",
    "section": "Course objectives and learning outcomes",
    "text": "Course objectives and learning outcomes\n\nCourse objectives\nAt the end of this course, students are able to:\n\nIdentify key statistical concepts such as:\n\n\n(Conditional) probability\nInference\nEstimation\nPrediction\nClassification\nSampling variability\nStatistical modeling\nResiduals Fitted values\n\n\nChoose an appropriate regression model for a given research scenario.\nExplain the differences/similarities between statistical inference and model-based prediction/classification; give examples of each type of problem.\nIdentify the assumptions of linear and logistic regression; describe the consequences of violating these assumptions.\nDescribe the three components of a generalized linear model and how these components are specified in logistic regression.\nInterpret the estimates from linear and logistic regression models, and use these estimates to answer research questions.\nUse the R statistical software platform to perform basic statistical programming, data manipulation, data visualization, and basic data wrangling.\nUse the R statistical software platform to perform, interpret, and evaluate linear and logistic regression analyses on real-world data.\nInterpret R output and use the results to answer research questions.\nUse Quarto to document the results of a statistical analysis.\n\n\n\nRationale for assessment strategy\nIn this course, skills and knowledge are evaluated with two types of assignment.\n\nThe exam evaluates knowledge and understanding of statistical concepts (Learning goal 1), the ability to critically evaluate research problems and statistical methods (Learning goals 2–5), and the ability to interpret statistical results and software output and apply these interpretations (Learning goals 6 & 9).\nThe group assignments evaluate the student’s ability to work with data, solve basic data analytic problems, execute quantitative data analyses on real-world data sets, and document the results (learning goals 6–10)."
  },
  {
    "objectID": "manual.html#important-notice-about-the-use-of-course-material",
    "href": "manual.html#important-notice-about-the-use-of-course-material",
    "title": "Course manual",
    "section": "Important notice about the use of course material",
    "text": "Important notice about the use of course material\nThe course material you receive in this course is intended for your personal learning process. All course content, including course manuals, presentations, recordings, (elaborations of) assignments and additional documents, is the intellectual property of Utrecht University. This material may not be shared, distributed or sold, both online and offline, without the express written permission of the university. NB: This also concerns entering course material in GenAI.\nWe would like to emphasize that taking this course is an investment in your own development. The material has been carefully put together to deepen your understanding of the field and strengthen your skills. By distributing or even selling this material, you violate the intellectual property of the UU. We therefore ask you to respect these guidelines and contribute to a fair and honest learning environment."
  },
  {
    "objectID": "manual.html#fraud-plagiarism-and-use-of-generative-ai",
    "href": "manual.html#fraud-plagiarism-and-use-of-generative-ai",
    "title": "Course manual",
    "section": "Fraud, plagiarism and use of generative AI",
    "text": "Fraud, plagiarism and use of generative AI\nPlagiarism and fraud are serious academic offenses. Plagiarism is defined as the use of another person’s work without proper acknowledgment. This includes copying and pasting text from the internet, from books, or from other students. If you use text from another source, you must put it in quotation marks and provide a citation. If you do not, you are committing plagiarism. Fraud is defined as the use of dishonest methods to gain an unfair advantage. This includes copying another student’s work, submitting work that is not your own, or submitting the same work for two different courses. If you commit fraud or plagiarism, you will fail the course. If you are not sure what constitutes plagiarism or fraud, please see the (UU Fraud and plagiarism policy)[https://students.uu.nl/en/practical-information/policies-and-procedures/fraud-and-plagiarism].\nThe use of generative AI (e.g., chatGPT) in the group assignments is allowed only for the following cases:\n\nGain inspiration\nAsk for help on how to tackle an assignment\n\nThe use of generative AI must be clearly indicated in the assignment, clearly identifying the specific model used and for what purpose. The use of generative AI for other purposes is not allowed."
  },
  {
    "objectID": "manual.html#course-content",
    "href": "manual.html#course-content",
    "title": "Course manual",
    "section": "",
    "text": "Regression techniques are widely used to quantify the relationship between two or more variables. In data science, linear and logistic regression are common and powerful techniques for evaluating such relations. These techniques are only useful, however, once you understand when and how to apply them. In this course, students will learn how to apply linear and logistic regression with the R statistical software package.\nThis course will introduce students to the principles of analytical data science, linear and logistic regression, and the basics of statistical learning. Students will develop fundamental R programming skills and will gain experience with tidyverse: visualize data with ggplot2 and performing basic data wrangling with dplyr. This course helps prepare students for an entry-level research career (e.g. junior researcher or research assistant) or further education in research (e.g., a [research] Master program or a PhD)."
  },
  {
    "objectID": "preperation.html#required-r-skills",
    "href": "preperation.html#required-r-skills",
    "title": "Preparation",
    "section": "",
    "text": "In this course, you will use both R and RStudio.\nIf you have never worked with R before, use the tutorials from Open Statistical Programming to be ready and prepared before the course starts. The materials discussed in the tutorials\n\nSoftware setup\nFirst steps\nData types\nWorkflow\nBasic visualizations\n\nare required knowledge before you start the course!"
  },
  {
    "objectID": "preperation.html#required-statistical-knowledge.",
    "href": "preperation.html#required-statistical-knowledge.",
    "title": "Preparation",
    "section": "Required statistical knowledge.",
    "text": "Required statistical knowledge."
  },
  {
    "objectID": "preperation.html#required-statistical-knowledge",
    "href": "preperation.html#required-statistical-knowledge",
    "title": "Preparation",
    "section": "Required statistical knowledge",
    "text": "Required statistical knowledge\nWe expect you to be familiar with some basic statistical concepts such as:\n\nDescriptive statistics\nSampling\nCorrelation\nT-test\nP-values\n\nTo refresh your memory, you can read SDAM Ch. 1, 2 and 3.\nThe course material builds on this knowledge, and it can also be part of the exam.\nNote: if you followed the course ADS-BOS, you have covered these topics and you should be good to go!"
  },
  {
    "objectID": "assignments.html#assignment-2",
    "href": "assignments.html#assignment-2",
    "title": "Assignments",
    "section": "Assignment 2",
    "text": "Assignment 2\ntext"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Both assignments are group assignments. We will form groups of 4 at the first workgroup meeting, and you work on both assignments with the same group throughout the rest of the course.\nIn order to be assigned to a group, presence at the first meeting is crucial!"
  },
  {
    "objectID": "assignments.html#assignment-1",
    "href": "assignments.html#assignment-1",
    "title": "Assignments",
    "section": "",
    "text": "text"
  },
  {
    "objectID": "assignments.html#assignment-1-linear-regression",
    "href": "assignments.html#assignment-1-linear-regression",
    "title": "Assignments",
    "section": "Assignment 1: Linear regression",
    "text": "Assignment 1: Linear regression\n\nType of assignment: Written report.\nGrading: 25% of your final grade\nDeadline: Monday December 8, 15:00\nWhat to submit: A ZIP archive containing the complete R project (dataset, .qmd, HTML)\nWhere to submit: This Surfdrive folder\nWhat is graded: Only your .html file is graded, so make sure all code, comments and output are visible!\nDescription: For this assignment, you perform and report a multiple linear regression analysis in an R markdown document. The assignment will be graded on the following five dimensions:\n\n\nPreliminaries: Introduction of your research questions, description and potential processing of your data.\nModel estimation: Description of the model estimates, model fit, and model comparison procedure.\nAssumptions: Testing of model assumptions, checking for influential cases. Act upon and/or reflect on violations when needed.\nInterpretation: Substantive interpretation of the final model. Answering your research question.\nLayout: Structure of the document, efficiency of output presentation, use of custom functions (when applicable). Presentation of suitable visualizations."
  },
  {
    "objectID": "assignments.html#assignment-2-logistic-regression",
    "href": "assignments.html#assignment-2-logistic-regression",
    "title": "Assignments",
    "section": "Assignment 2: Logistic regression",
    "text": "Assignment 2: Logistic regression\nGroup assignment 2: Logistic regression\n\nType of assignment: Presentation and discussion\nGrading: 25% of your final grade\nPresentation: WG meeting Thursday January 15\nDeadline: Wednesday January 14, 15:00. Hand in your ZIP archive including your slides. Your WG instructor will set the slides up for the presentations on Thursday.\nWhat to submit: A ZIP archive containing the complete R project (dataset, .qmd, slides)\nWhere to submit: This Surfdrive folder\nDescription: For this assignment, you perform and report a multiple logistic regression analysis in an R markdown document. The assignment will be graded on the following five dimensions:\n\n\nPreliminaries: Introduction of your research questions, description and potential processing of your data.\nModel estimation: Description of the model estimates, model fit, and model comparison procedure.\nAssumptions: Testing of model assumptions, checking for influential cases. Act upon and/or reflect on violations when needed.\nInterpretation: Substantive interpretation of the final model (including the confusion matrix). Answering your research question.\nLayout: Structure of the document, efficiency of output presentation, use of custom functions (when applicable). Presentation of suitable visualizations."
  },
  {
    "objectID": "exam.html#what-can-i-expect-regarding-the-exam",
    "href": "exam.html#what-can-i-expect-regarding-the-exam",
    "title": "Exam",
    "section": "What can I expect regarding the exam?",
    "text": "What can I expect regarding the exam?\nThe exam takes place on January 22. Keep an eye out on MyTimetable for the timing, location. These can change very last-minute!\nThe exam takes place on laptops that are provided in the room, and we use the software program Remindo. Please read the instructions on how to use Remindo carefully. You can also practice making an exam in Remindo. Remindo has a small built-in calculator, so you don’t need to bring one.\nRegulations during the exam:\n\nTurn of your phone and smartwatch and stow them away. You cannot use them in any way during the exam.\nYou are not allowed to use any teaching materials or dictionaries during the exam.\nClose your bag and do not store it in the walkway.\nYou cannot leave in the first 30 minutes.\nYou are not allowed to visit the bathroom during the exam.\nMake sure your ID is visible on your table during the exam.\nIf you are more than 30 minutes late to the exam, you are not allowed to participate.\n\nWhat to bring:\n\nIdentification card.\nSolid ID and password for logging in to Remindo."
  },
  {
    "objectID": "exam.html#what-will-be-tested",
    "href": "exam.html#what-will-be-tested",
    "title": "Exam",
    "section": "",
    "text": "Anything mentioned in the lectures may appear on the exam.\nThis includes both information printed in the lecture slides and information delivered verbally during a lecture itself.Anything covered in the required readings may appear on the exam.\nObviously, this is a lot of material. To prioritize, keep in mind that topics mentioned in the lectures and topics directly related to ideas covered in the lectures are most likely to appear on the exam.\nThe materials presented on the “preparation” page can also be part of the exam since this is required knowledge.\nSummary of the required readings:\n\nR4DS: Ch. 1, 3, 4, 7, 9, 10, 13, 16.\nSDAM: Ch. 1, 2, 3, 4, 5, 6.1, 12.1-12.5, 12.8.\nBook420: Ch.17.4.\nhttps://stats.oarc.ucla.edu/r/dae/robust-regression/\nhttps://stats.oarc.ucla.edu/r/dae/robust-regression/\nhttps://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/\nhttps://stats.oarc.ucla.edu/r/dae/logit-regression/"
  },
  {
    "objectID": "exam.html#what-about-equations",
    "href": "exam.html#what-about-equations",
    "title": "Exam",
    "section": "What about equations?",
    "text": "What about equations?\nThis is not a math class; we are not trying to test your ability to do calculations or manipulate equations. That being said, a certain degree of mathematical literacy is crucial to statistics and data science, so you will have to do some simple calculations on the exam. For example, you should be comfortable with the following.\n\nWorking with the linear regression equation, \\(Y_i = \\beta_0 + \\beta_1 X_i +\\varepsilon_i\\), to:\n\nCalculate predicted values give certain inputs\nInterpret parameter estimates\nEvaluate hypotheses/research questions\n\nThe differences between:\n\nThe full regression model: \\(Y_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_i +\\hat{\\varepsilon}_i\\)\nThe equation for the best-fit line: \\(\\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_i\\)\n\nThe definition of a residual:\n\n\\(\\hat{\\varepsilon}_i = Y_i - \\hat{Y}_i\\)\n\nThe relationship between probabilities (\\(p\\)) and odds (for binary outcomes):\n\n\\(\\text{odds} = \\frac{p}{1-p}\\)\n\nThe definition of the logit function:\n\n\\(\\ln(\\text{odds}) = \\ln\\left(\\frac{p}{1-p}\\right) = \\text{logit}(p)\\)\n\nThe definition of the logistic function, its relation to the logit function, and its role in logistic regression:\n\n\\(\\text{logistic}(\\eta_i) = \\text{logit}^{-1}(p_i) = \\frac{\\exp(\\eta_i)}{1+\\exp(\\eta_i)} = \\frac{\\exp(\\hat{\\beta}_0 + \\hat{\\beta}_1 X_i)}{1 + \\exp(\\hat{\\beta}_0 + \\hat{\\beta}_1 X_i)} = \\hat{p}_i\\)\n\n\nOf course, you should also be able to do basic arithmetic operations that are too trivial to detail here (e.g., calculating the difference between the \\(R^2\\) statistics from two models that you are trying to compare).\nNote: Although all examples above are shown in terms of simple linear regression models, you should also be able to do these calculations/interpretations using multiple linear regression models and models that include dummy codes and interactions."
  },
  {
    "objectID": "exam.html#practice-exam",
    "href": "exam.html#practice-exam",
    "title": "Exam",
    "section": "Practice exam",
    "text": "Practice exam\nA link to a practice exam will be provided later"
  },
  {
    "objectID": "exam.html#qa-and-practice-exam",
    "href": "exam.html#qa-and-practice-exam",
    "title": "Exam",
    "section": "Q&A and practice exam",
    "text": "Q&A and practice exam\n\nThe lecture on Monday January 12 will be completely devoted to a recap of the material and there will be plenty of time to answer all your questions. Send your questions in advance to Dr. Lang if you want to make sure you get an extensive answer!\nA link to a practice exam will be provided later."
  },
  {
    "objectID": "labs/lab1.html",
    "href": "labs/lab1.html",
    "title": "Lab 1",
    "section": "",
    "text": "From the Open Statistical Programming modules, complete the following:\n\nReproducible reporting\nExternal data\nData manipulation\nFunctions advanced\nIteration"
  },
  {
    "objectID": "labs/lab2.html",
    "href": "labs/lab2.html",
    "title": "Lab 2",
    "section": "",
    "text": "From the Open Statistical Programming modules, complete the following:\n\nDescriptive statistics\nGGplot"
  },
  {
    "objectID": "labs/lab2.html#loading-the-dataset",
    "href": "labs/lab2.html#loading-the-dataset",
    "title": "Lab 2",
    "section": "Loading the dataset",
    "text": "Loading the dataset\nIn the this practical, we will use the built-in data set iris. This data set contains the measurement of different iris species (flowers), you can find more information here.\n\nLoad the dataset and explain what variables are measured in the first three columns of your data set."
  },
  {
    "objectID": "labs/lab2.html#inspecting-the-dataset",
    "href": "labs/lab2.html#inspecting-the-dataset",
    "title": "Lab 2",
    "section": "Inspecting the dataset",
    "text": "Inspecting the dataset\nA good way of eyeballing on a relation between two continuous variables is by creating a scatterplot.\n\nPlot the sepal length and the petal width variables in a ggplot scatter plot (geom_points)\n\nA loess curve can be added to the plot to get a general idea of the relation between the two variables. You can add a loess curve to a ggplot with stat_smooth(method = \"loess\").\n\nAdd a loess curve to the plot under question 2, for further inspection.\n\nTo get a clearer idea of the general trend in the data (or of the relation), a regression line can be added to the plot. A regression line can be added in the same way as a loess curve, the method argument in the function needs to be altered to lm to do so.\n\nChange the loess curve of the previous plot to a regression line. Describe the relation that the line indicates."
  },
  {
    "objectID": "labs/lab2.html#simple-linear-regression",
    "href": "labs/lab2.html#simple-linear-regression",
    "title": "Lab 2",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nWith the lm() function, you can specify a linear regression model. You can save a model in an object and request summary statistics with the summary() command. The model is always specified with the code outcome_variable ~ predictor.\nWhen a model is stored in an object, you can ask for the coefficients with coefficients(). The next code block shows how you would specify a model where petal width is predicted by sepal width, and how summary statistics for this model would look like\n\n# Specify model: outcome = petal width, predictor = sepal width\niris_model1 &lt;- lm(Petal.Width ~ Sepal.Width,\n                  data = iris)\n\nsummary(iris_model1)\n\n\nCall:\nlm(formula = Petal.Width ~ Sepal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38424 -0.60889 -0.03208  0.52691  1.64812 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.1569     0.4131   7.642 2.47e-12 ***\nSepal.Width  -0.6403     0.1338  -4.786 4.07e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7117 on 148 degrees of freedom\nMultiple R-squared:  0.134, Adjusted R-squared:  0.1282 \nF-statistic: 22.91 on 1 and 148 DF,  p-value: 4.073e-06\n\n\nThe summary of the model provides:\n\nThe model formula;\nEstimated coefficients (with standard errors and their significance tests);\nInformation on the residuals;\nA general test for the significance of the model (F-test);\nThe (adjusted) R squared as a metric for model performance.\n\nIndividual elements can be extracted by calling specific model elements (e.g. iris_model1$coefficients).\n\nSpecify a regression model where Sepal length is predicted by Petal width. Store this model as `model1. Supply summary statistics for this model.\nBased on the summary of the model, give a substantive interpretation of the regression coefficient.\nRelate the summary statistics and coefficients to the plots you made in questions 2 - 4."
  },
  {
    "objectID": "labs/{{ 'lab2_answers' if params.answer else 'lab2' }}.html",
    "href": "labs/{{ 'lab2_answers' if params.answer else 'lab2' }}.html",
    "title": "Lab 2",
    "section": "",
    "text": "From the Open Statistical Programming modules, complete the following:\n\nDescriptive statistics\nGGplot"
  },
  {
    "objectID": "labs/{{ 'lab2_answers' if params.answer else 'lab2' }}.html#loading-the-dataset",
    "href": "labs/{{ 'lab2_answers' if params.answer else 'lab2' }}.html#loading-the-dataset",
    "title": "Lab 2",
    "section": "Loading the dataset",
    "text": "Loading the dataset\nIn the this practical, we will use the built-in data set iris. This data set contains the measurement of different iris species (flowers), you can find more information here.\n\nLoad the dataset and explain what variables are measured in the first three columns of your data set.\n\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa"
  },
  {
    "objectID": "labs/{{ 'lab2_answers' if params.answer else 'lab2' }}.html#inspecting-the-dataset",
    "href": "labs/{{ 'lab2_answers' if params.answer else 'lab2' }}.html#inspecting-the-dataset",
    "title": "Lab 2",
    "section": "Inspecting the dataset",
    "text": "Inspecting the dataset\nA good way of eyeballing on a relation between two continuous variables is by creating a scatterplot.\n\nPlot the sepal length and the petal width variables in a ggplot scatter plot (geom_points)\n\n\n\n\n\n\n\n\n\n\nA loess curve can be added to the plot to get a general idea of the relation between the two variables. You can add a loess curve to a ggplot with stat_smooth(method = \"loess\").\n\nAdd a loess curve to the plot under question 2, for further inspection.\n\n\n\n\n\n\n\n\n\n\nTo get a clearer idea of the general trend in the data (or of the relation), a regression line can be added to the plot. A regression line can be added in the same way as a loess curve, the method argument in the function needs to be altered to lm to do so.\n\nChange the loess curve of the previous plot to a regression line. Describe the relation that the line indicates."
  },
  {
    "objectID": "labs/{{ 'lab2_answers' if params.answer else 'lab2' }}.html#simple-linear-regression",
    "href": "labs/{{ 'lab2_answers' if params.answer else 'lab2' }}.html#simple-linear-regression",
    "title": "Lab 2",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nWith the lm() function, you can specify a linear regression model. You can save a model in an object and request summary statistics with the summary() command. The model is always specified with the code outcome_variable ~ predictor.\nWhen a model is stored in an object, you can ask for the coefficients with coefficients(). The next code block shows how you would specify a model where petal width is predicted by sepal width, and how summary statistics for this model would look like\n\n\n\nCall:\nlm(formula = Petal.Width ~ Sepal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38424 -0.60889 -0.03208  0.52691  1.64812 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.1569     0.4131   7.642 2.47e-12 ***\nSepal.Width  -0.6403     0.1338  -4.786 4.07e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7117 on 148 degrees of freedom\nMultiple R-squared:  0.134, Adjusted R-squared:  0.1282 \nF-statistic: 22.91 on 1 and 148 DF,  p-value: 4.073e-06\n\n\nThe summary of the model provides:\n\nThe model formula;\nEstimated coefficients (with standard errors and their significance tests);\nInformation on the residuals;\nA general test for the significance of the model (F-test);\nThe (adjusted) R squared as a metric for model performance.\n\nIndividual elements can be extracted by calling specific model elements (e.g. iris_model1$coefficients).\n\nSpecify a regression model where Sepal length is predicted by Petal width. Store this model as `model1. Supply summary statistics for this model.\n\n\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Width, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38822 -0.29358 -0.04393  0.26429  1.34521 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.77763    0.07293   65.51   &lt;2e-16 ***\nPetal.Width  0.88858    0.05137   17.30   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.478 on 148 degrees of freedom\nMultiple R-squared:  0.669, Adjusted R-squared:  0.6668 \nF-statistic: 299.2 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n\nBased on the summary of the model, give a substantive interpretation of the regression coefficient.\n\n\nRelate the summary statistics and coefficients to the plots you made in questions 2 - 4."
  },
  {
    "objectID": "labs/lab2_answers.html",
    "href": "labs/lab2_answers.html",
    "title": "Lab 2",
    "section": "",
    "text": "From the Open Statistical Programming modules, complete the following:\n\nDescriptive statistics\nGGplot"
  },
  {
    "objectID": "labs/lab2_answers.html#loading-the-dataset",
    "href": "labs/lab2_answers.html#loading-the-dataset",
    "title": "Lab 2",
    "section": "Loading the dataset",
    "text": "Loading the dataset\nIn the this practical, we will use the built-in data set iris. This data set contains the measurement of different iris species (flowers), you can find more information here.\n\nLoad the dataset and explain what variables are measured in the first three columns of your data set.\n\n\ndata &lt;- iris # load the data\nhead(iris)   # inspect the data\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n# The data set contains three different kinds of flowers. The petal leaves and sepal leaves are measured in length and width. All measurements are in centimeters."
  },
  {
    "objectID": "labs/lab2_answers.html#inspecting-the-dataset",
    "href": "labs/lab2_answers.html#inspecting-the-dataset",
    "title": "Lab 2",
    "section": "Inspecting the dataset",
    "text": "Inspecting the dataset\nA good way of eyeballing on a relation between two continuous variables is by creating a scatterplot.\n\nPlot the sepal length and the petal width variables in a ggplot scatter plot (geom_points)\n\n\nggplot(data) +\n  geom_point(aes(Sepal.Length, Petal.Width)) +\n  xlab(\"Sepal length (in cm)\") +\n  ylab(\"Petal width (in cm)\") +\n  labs(col = \"Species\") +\n  theme_minimal() +\n  ggtitle(\"Plot of 2 continous variables\")  + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nA loess curve can be added to the plot to get a general idea of the relation between the two variables. You can add a loess curve to a ggplot with stat_smooth(method = \"loess\").\n\nAdd a loess curve to the plot under question 2, for further inspection.\n\n\nggplot(data, aes(x = Sepal.Length, y = Petal.Width)) +\n  geom_point() +\n  stat_smooth(method = \"loess\", se=F, col = \"blue\") +\n  xlab(\"Sepal length (in cm)\") +\n  ylab(\"Petal width (in cm)\") +\n  labs(col = \"Species\") +\n  theme_minimal() +\n  ggtitle(\"Plot of 2 continous variables\")  + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n# The curve is added to the previous plot by the line `stat_smooth(method = \"loess, se = F, col = \"blue\")`.\n\nTo get a clearer idea of the general trend in the data (or of the relation), a regression line can be added to the plot. A regression line can be added in the same way as a loess curve, the method argument in the function needs to be altered to lm to do so.\n\nChange the loess curve of the previous plot to a regression line. Describe the relation that the line indicates.\n\n\n# In comparison to the previous plot, we now adjust \"method = \"loess\"\" to \"method = \"lm\"\".\nggplot(data, aes(x = Sepal.Length, y = Petal.Width)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se=F, col = \"blue\") +\n  xlab(\"Sepal length (in cm)\") +\n  ylab(\"Petal width (in cm)\") +\n  labs(col = \"Species\") +\n  theme_minimal() +\n  ggtitle(\"Plot of 2 continous variables\")  + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n# The line indicates that there seems to be a more or less linear positive relation between the two plotted variables. This means that an increase in sepal length probably indicates an increase in petal width as well."
  },
  {
    "objectID": "labs/lab2_answers.html#simple-linear-regression",
    "href": "labs/lab2_answers.html#simple-linear-regression",
    "title": "Lab 2",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nWith the lm() function, you can specify a linear regression model. You can save a model in an object and request summary statistics with the summary() command. The model is always specified with the code outcome_variable ~ predictor.\nWhen a model is stored in an object, you can ask for the coefficients with coefficients(). The next code block shows how you would specify a model where petal width is predicted by sepal width, and how summary statistics for this model would look like\n\n# Specify model: outcome = petal width, predictor = sepal width\niris_model1 &lt;- lm(Petal.Width ~ Sepal.Width,\n                  data = iris)\n\nsummary(iris_model1)\n\n\nCall:\nlm(formula = Petal.Width ~ Sepal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38424 -0.60889 -0.03208  0.52691  1.64812 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.1569     0.4131   7.642 2.47e-12 ***\nSepal.Width  -0.6403     0.1338  -4.786 4.07e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7117 on 148 degrees of freedom\nMultiple R-squared:  0.134, Adjusted R-squared:  0.1282 \nF-statistic: 22.91 on 1 and 148 DF,  p-value: 4.073e-06\n\n\nThe summary of the model provides:\n\nThe model formula;\nEstimated coefficients (with standard errors and their significance tests);\nInformation on the residuals;\nA general test for the significance of the model (F-test);\nThe (adjusted) R squared as a metric for model performance.\n\nIndividual elements can be extracted by calling specific model elements (e.g. iris_model1$coefficients).\n\nSpecify a regression model where Sepal length is predicted by Petal width. Store this model as `model1. Supply summary statistics for this model.\n\n\n# specify model\nmodel1 &lt;- lm(Sepal.Length ~ Petal.Width, \n             data = data)\n\n# ask for summary\nsummary(model1)\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Width, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38822 -0.29358 -0.04393  0.26429  1.34521 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.77763    0.07293   65.51   &lt;2e-16 ***\nPetal.Width  0.88858    0.05137   17.30   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.478 on 148 degrees of freedom\nMultiple R-squared:  0.669, Adjusted R-squared:  0.6668 \nF-statistic: 299.2 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n\nBased on the summary of the model, give a substantive interpretation of the regression coefficient.\n\n\n# The regression coefficient indicates the amount of change in the predicted variable when the predictor variable is changed with one unit. In case of the example model, this means that for every centimeter increase in the width of a petal leaf, the predicted length of a sepal leaf increases by 0.89 cm.\n\n\nRelate the summary statistics and coefficients to the plots you made in questions 2 - 4.\n\n\n# The coefficients seem to be in accordance with the earlier plots. They are not exactly the same, but indicate a similar positive relationship."
  },
  {
    "objectID": "labs/lab3.html",
    "href": "labs/lab3.html",
    "title": "Lab 3",
    "section": "",
    "text": "In this practical, the assumptions of the linear regression model will be discussed. You will practice with checking the different assumptions, and practice with accounting for some of the assumptions with additional steps. Please note that these assumptions can only be checked once you have selected a (final) model, as these assumptions ‘need’ a model that they apply to.\nWe will use the following packages in this practical:\n\nlibrary(magrittr)\nlibrary(ggplot2) \nlibrary(regclass)\nlibrary(MASS)"
  },
  {
    "objectID": "labs/lab3.html#categorical-predictors",
    "href": "labs/lab3.html#categorical-predictors",
    "title": "Lab 3",
    "section": "Categorical predictors",
    "text": "Categorical predictors\nUp to here, we only included continuous predictors in our models. We will now include a categorical predictor in the model as well.\nWhen a categorical predictor is added, this predictor is split in several contrasts (or dummies), where each group is compared to a reference group. In our example Iris data, the variable ‘Species’ is a categorical variable that indicate the species of flower. This variable can be added as example for a categorical predictor. Contrasts, and thus the dummy coding, can be inspected through contrasts().\n\nAdd species as a predictor to the model specified as model2, store it under the name model3 and interpret the categorical coefficients of this new model."
  },
  {
    "objectID": "labs/lab3.html#calculating-new-predicted-values",
    "href": "labs/lab3.html#calculating-new-predicted-values",
    "title": "Lab 3",
    "section": "Calculating new predicted values",
    "text": "Calculating new predicted values\nA regression model can be used to predict values for new cases that were not used to built the model. The regression equation always consists of coefficients (\\(\\beta\\)s) and observed variables (\\(X\\)):\n\n\\[\\hat{y} = \\beta_0 + \\beta_1 * X_{a}* + \\beta_2 * X_b +  \\ldots  + \\beta_n * X_n\\]"
  },
  {
    "objectID": "labs/lab3_answers.html",
    "href": "labs/lab3_answers.html",
    "title": "Lab 3",
    "section": "",
    "text": "We will use the following packages in this practical:\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(gridExtra)\n\nWe will use the same data that we used last week to perform a simple linear regression, the Iris dataset. But now, we will extend on this simple model with multiple variables.\nIn order to do this, we first need to load the data again and run the simple model where Sepal length is predicted by Petal width.\n\ndata &lt;- iris # load the data\nhead(iris)   # inspect the data\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\n# specify model\nmodel1 &lt;- lm(Sepal.Length ~ Petal.Width, \n             data = data)\n\n# ask for summary\nsummary(model1)\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Width, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38822 -0.29358 -0.04393  0.26429  1.34521 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.77763    0.07293   65.51   &lt;2e-16 ***\nPetal.Width  0.88858    0.05137   17.30   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.478 on 148 degrees of freedom\nMultiple R-squared:  0.669, Adjusted R-squared:  0.6668 \nF-statistic: 299.2 on 1 and 148 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "labs/lab3_answers.html#categorical-predictors",
    "href": "labs/lab3_answers.html#categorical-predictors",
    "title": "Lab 3",
    "section": "Categorical predictors",
    "text": "Categorical predictors\nUp to here, we only included continuous predictors in our models. We will now include a categorical predictor in the model as well.\nWhen a categorical predictor is added, this predictor is split in several contrasts (or dummies), where each group is compared to a reference group. In our example Iris data, the variable ‘Species’ is a categorical variable that indicate the species of flower. This variable can be added as example for a categorical predictor. Contrasts, and thus the dummy coding, can be inspected through contrasts().\n\nAdd species as a predictor to the model specified as model2, store it under the name model3 and interpret the categorical coefficients of this new model.\n\n\n# Create 3rd model with categorical predictor\nmodel3 &lt;- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Species,\n             data = data)\n\n# Ask for summary data\nsummary(model3)\n\n\nCall:\nlm(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Species, \n    data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.82156 -0.20530  0.00638  0.22645  0.74999 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        2.39039    0.26227   9.114 5.94e-16 ***\nSepal.Width        0.43222    0.08139   5.310 4.03e-07 ***\nPetal.Length       0.77563    0.06425  12.073  &lt; 2e-16 ***\nSpeciesversicolor -0.95581    0.21520  -4.442 1.76e-05 ***\nSpeciesvirginica  -1.39410    0.28566  -4.880 2.76e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3103 on 145 degrees of freedom\nMultiple R-squared:  0.8633,    Adjusted R-squared:  0.8595 \nF-statistic: 228.9 on 4 and 145 DF,  p-value: &lt; 2.2e-16\n\n# In the output, we see that 'Species' has multiple rows of output, and that one species (Setosa) does not seem to show. Setosa is the reference group. The other two lines are those respecitve groups compared to the setosa group. This means that that the predicted sepal length of a versicolor would be .9558 lower than the predicted value of a setosas with the same values on the other variables."
  },
  {
    "objectID": "labs/lab3_answers.html#calculating-new-predicted-values",
    "href": "labs/lab3_answers.html#calculating-new-predicted-values",
    "title": "Lab 3",
    "section": "Calculating new predicted values",
    "text": "Calculating new predicted values\nA regression model can be used to predict values for new cases that were not used to built the model. The regression equation always consists of coefficients (\\(\\beta\\)s) and observed variables (\\(X\\)):\n\n\\[\\hat{y} = \\beta_0 + \\beta_1 * X_{a}* + \\beta_2 * X_b +  \\ldots  + \\beta_n * X_n\\]"
  },
  {
    "objectID": "labs/lab3.html#linearity",
    "href": "labs/lab3.html#linearity",
    "title": "Lab 3",
    "section": "Linearity",
    "text": "Linearity\nWith the assumption of linearity, it is assumed that the relation between the dependent and independent variables is (more or less) linear. You can check this by generating a scatterplot using a predictor variable and outcome variable of the regression model.\n\nCheck whether there is a linear relation between the variables vertical length and the cross length.\nNext check the relation between weight and height.\nDescribe both plots. What differences do you see?\n\nWhen a non-linear relation is present, you can either choose another model to use, or transform the predictor before adding it to the model, for example using a log-transformation. Applying a transformation, however, will not always solve the problem, and makes interpretation of the model less intuitive.\n\nApply a log-transformation to the weight variable.\nPlot the relation between length and weight again, but now including the transformed variable.\nDescribe if the transformation improved the linear relation."
  },
  {
    "objectID": "labs/lab3.html#predictor-matrix-full-rank",
    "href": "labs/lab3.html#predictor-matrix-full-rank",
    "title": "Lab 3",
    "section": "Predictor matrix full rank",
    "text": "Predictor matrix full rank\nThis assumption states that:\n\nthere need to be more observations than predictors (n &gt; P).\n\nno predictor can be a linear combination of other predictors; predictors cannot have a very high correlation (multicollinearity).\n\n\nThe first part of this assumption is easy to check: see if the number of observations minus the number of predictors is a positive number. The second part can be checked by either obtaining correlations between the predictors, or by determining the VIF (variance inflation factor). When the VIF is above 10, this indicate high multicollinearity. To account for this, predictors can be excluded from the model, or a new variable can be constructed based on predictors with a high correlation.\nTo examine VIF scores, the function VIF() from the regclass can be used on a prespecified model. If this model includes a categorical variable with multiple categories, such as ‘species’ in the example data, the generalized VIF is used, and we have to look at the third column (GVIF^*(1/(2*Df))), these values can be compared to normal VIF values.\n\nSpecify a linear model with weight as outcome variable using all other variables in the dataset as predictors. Save this model as model_fish1. Calculate VIF values for this model.\nCheck the VIF scores. If VIF scores exceed a score of 10, give substantial explanation why the VIF scores are this high.\nWhat adjustments can be made to the model to account for multicollinearity in this case?\nRun a new model which only includes one of the three length variables and call it model_fish2. Describe if there is an improvement.\nWhat happens with the regression model when there are more predictors than observations?"
  },
  {
    "objectID": "labs/lab3.html#exogenous-predictors",
    "href": "labs/lab3.html#exogenous-predictors",
    "title": "Lab 3",
    "section": "Exogenous predictors",
    "text": "Exogenous predictors\nFor this assumption, the expected value of the errors (mean of the errors) must be 0. Furthermore, The errors must be independent of the predictors.\n\nWhat is the possible consequence of not meeting this assumption?"
  },
  {
    "objectID": "labs/lab3.html#constant-finite-error-variance",
    "href": "labs/lab3.html#constant-finite-error-variance",
    "title": "Lab 3",
    "section": "Constant, finite error variance",
    "text": "Constant, finite error variance\nThis assumptions is also called ‘the assumption of homoscedasticity’. It states that the variance of the error terms should be constant over all levels of the predictors. This can be checked by plotting the residuals against the fitted values. These plots can be obtained by simply taking the first plot of a specified model, plot(model_x).\n\nCreate a residual vs fitted values plot for model_fish1, which is the first plot generated by the plot() function.\nLoad in the iris data, and specify a model where sepal length is predicted by all other variables and save this as model_iris1.\nCreate a residual vs fitted plot for this model as well.\nDiscuss both plots and indicate whether the assumption is met.\nDiscuss what the consequence would be if this assumption is violated."
  },
  {
    "objectID": "labs/lab3.html#independent-errors",
    "href": "labs/lab3.html#independent-errors",
    "title": "Lab 3",
    "section": "Independent errors",
    "text": "Independent errors\nThis assumption states that error terms should have no correlation. Dependence of the errors can result from multiple things. First, there is a possible dependence in the error terms when there is serial dependence, for example because the data contains variables that are measured over time. Another reason can be when there is a cluster structure in the data, for example students in classes in schools.\n\nHow can both causes of correlated error terms be detected, and what can be done to solve the problem?"
  },
  {
    "objectID": "labs/lab3.html#normally-distributed-errors",
    "href": "labs/lab3.html#normally-distributed-errors",
    "title": "Lab 3",
    "section": "Normally distributed errors",
    "text": "Normally distributed errors\nThis assumption states that errors should be roughly normally distributed. Like the assumption of homoscedasticity, this can be checked by model plots, provided by R.\n\nCreate a QQ plot for model_iris1, which is the second plot generated by the plot() function. Indicate whether the assumption is met.\nCreate a new model using the fish data, where diagonal_width is predicted by cross_length, and store the model as model_fish3.\nCreate a QQ plot for model_fish3.\nInterpret the two plots. Is the assumption met in both cases?\nIn what cases is it problematic that the assumption is not met? And in what cases is it no problem?"
  },
  {
    "objectID": "labs/lab3.html#outliers",
    "href": "labs/lab3.html#outliers",
    "title": "Lab 3",
    "section": "Outliers",
    "text": "Outliers\nOutliers are observations that show extreme outcomes compared to the other data, or observations with outcome values that fit the model very badly. Outliers can be detected by inspecting the externally studentized residuals.\n\nMake a plot of studentized residuals by using the functions rstudent and plot for `model_fish1. What do you conclude?\nMake a plot of studentized residuals for model_iris1.\nStore the dataset Animals from the MASS package. Define a regression model where animals’ body weight is predicted by brain weight and store it as model_animals1.\nMake a plot of the studentized residuals for model_animals1."
  },
  {
    "objectID": "labs/lab3.html#high-leverage-observations",
    "href": "labs/lab3.html#high-leverage-observations",
    "title": "Lab 3",
    "section": "High-leverage observations",
    "text": "High-leverage observations\nHigh-leverage observations are observations with extreme predictor values. To detect these observations, we look at their leverage values. These values can be summarized in a leverage plot.\n\nFor the model specified under model_animals1, create a leverage plot by plotting the hatvalues() of the model."
  },
  {
    "objectID": "labs/lab3.html#influence-on-the-model",
    "href": "labs/lab3.html#influence-on-the-model",
    "title": "Lab 3",
    "section": "Influence on the model",
    "text": "Influence on the model\nBoth outliers and observations with high leverage are not necessarily a problem. Cases that are both, however, seem to form more of a problem. These cases can influence the model heavily and can therefore be problematic.\nInfluence measures come in two sorts: Cook’s distance checks for influential observations, while DFBETAS check for influential, and possible problematic, observations per regression coefficients.\n\nFor model_animals1, check Cooks distance by plotting the cooks.distance of the model.\nFor model_animals1, check the DFBETAS by using the function dfbetas.\nDescribe what you see in the plots for Cook’s distance and DFBETAS. What do you conclude?\nDelete the problematic observation that you found in Question 12 and store the dataset under a new name.\nFit the regression model where animals’ body weight is predicted by brain weight using the adjusted dataset and store it as model_animals2.\nCompare the output to model_animals1 and describe the changes.\nRun the plots for influential observations again on this new model and see if anything changes."
  },
  {
    "objectID": "labs/lab4_answers.html",
    "href": "labs/lab4_answers.html",
    "title": "Lab 4",
    "section": "",
    "text": "In this practical, the assumptions of the linear regression model will be discussed. You will practice with checking the different assumptions, and practice with accounting for some of the assumptions with additional steps. Please note that these assumptions can only be checked once you have selected a (final) model, as these assumptions ‘need’ a model that they apply to.\nWe will use the following packages in this practical:\n\nlibrary(magrittr)\nlibrary(ggplot2) \nlibrary(regclass)\nlibrary(MASS)"
  },
  {
    "objectID": "labs/lab4_answers.html#linearity",
    "href": "labs/lab4_answers.html#linearity",
    "title": "Lab 4",
    "section": "Linearity",
    "text": "Linearity\nWith the assumption of linearity, it is assumed that the relation between the dependent and independent variables is (more or less) linear. You can check this by generating a scatterplot using a predictor variable and outcome variable of the regression model.\n\nCheck whether there is a linear relation between the variables vertical length and the cross length.\n\n\nggplot(data_fish, \n       aes(x = vertical_length, y = cross_length)) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  ggtitle(\"linear relation is present\") +\n  xlab(\"vertical length in cm\") +\n  ylab(\"cross length in cm\")\n\n\n\n\n\n\n\n\n\nNext check the relation between weight and height.\n\n\nggplot(data_fish, aes(x = weigth, y = height)) + \n  geom_point() +\n  geom_smooth(se = FALSE) +\n  ggtitle(\"linear relation is missing\") +\n  xlab(\"Weigth in gram\") +\n  ylab(\"heigth in cm\")\n\n\n\n\n\n\n\n\n\nDescribe both plots. What differences do you see?\n\n\n# The first plot shows a case where there is a more or less linear relation (Vertical length of the fish and cross length of the fish). In the second plot, the relation is clearly not linear.\n\nWhen a non-linear relation is present, you can either choose another model to use, or transform the predictor before adding it to the model, for example using a log-transformation. Applying a transformation, however, will not always solve the problem, and makes interpretation of the model less intuitive.\n\nApply a log-transformation to the weight variable.\n\n\ndata_fish$weigth_trans &lt;- data_fish$weigth %&gt;% \n  log()\n\n\nPlot the relation between length and weight again, but now including the transformed variable.\n\n\nggplot(data_fish, aes(x = weigth_trans, y = height)) + \n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  ggtitle(\"linear relation improved\") +\n  xlab(\"Weigth in gram\") +\n  ylab(\"heigth in cm\")\n\n\n\n\n\n\n\n\n\nDescribe if the transformation improved the linear relation.\n\n\n# You see that the relation is still not completely linear, but a lot more linear than before the transformation (plot 2)."
  },
  {
    "objectID": "labs/lab4_answers.html#predictor-matrix-full-rank",
    "href": "labs/lab4_answers.html#predictor-matrix-full-rank",
    "title": "Lab 4",
    "section": "Predictor matrix full rank",
    "text": "Predictor matrix full rank\nThis assumption states that:\n\nthere need to be more observations than predictors (n &gt; P).\n\nno predictor can be a linear combination of other predictors; predictors cannot have a very high correlation (multicollinearity).\n\n\nThe first part of this assumption is easy to check: see if the number of observations minus the number of predictors is a positive number. The second part can be checked by either obtaining correlations between the predictors, or by determining the VIF (variance inflation factor). When the VIF is above 10, this indicate high multicollinearity. To account for this, predictors can be excluded from the model, or a new variable can be constructed based on predictors with a high correlation.\nTo examine VIF scores, the function VIF() from the regclass can be used on a prespecified model. If this model includes a categorical variable with multiple categories, such as ‘species’ in the example data, the generalized VIF is used, and we have to look at the third column (GVIF^*(1/(2*Df))), these values can be compared to normal VIF values.\n\nSpecify a linear model with weight as outcome variable using all other variables in the dataset as predictors. Save this model as model_fish1. Calculate VIF values for this model.\n\n\nmodel_fish1 &lt;- lm(weigth ~., \n                  data = data_fish[,1:7])\n\nmodel_fish1 %&gt;%\n  VIF()\n\n                      GVIF Df GVIF^(1/(2*Df))\nspecies         1509.77571  6        1.840388\nvertical_length 2360.42508  1       48.584206\ndiagonal_length 4307.91811  1       65.634732\ncross_length    2076.93715  1       45.573426\nheight            56.20370  1        7.496913\ndiagonal_width    29.16651  1        5.400602\n\n\n\nCheck the VIF scores. If VIF scores exceed a score of 10, give substantial explanation why the VIF scores are this high.\n\n\n# The VIF values in this first model are extreme in some cases, more specifically for the three variables that all measure some aspect of length, it makes sense that these values can be highly correlated. One way to solve this, is excluding predictors that almost measure the same thing as another variable.\n\n\nWhat adjustments can be made to the model to account for multicollinearity in this case?\n\n\n# A straightforward solution is to include only one of the variables measuring an aspect of length. More elaborate solutions exist but are not covered in this course.\n\n\nRun a new model which only includes one of the three length variables and call it model_fish2. Describe if there is an improvement.\n\n\nmodel_fish2 &lt;- lm(weigth ~ species + diagonal_length + height + diagonal_width, \n             data = data_fish)\n\nmodel_fish2 %&gt;%\n  VIF()\n\n                     GVIF Df GVIF^(1/(2*Df))\nspecies         218.36805  6        1.566507\ndiagonal_length  28.17950  1        5.308437\nheight           54.91084  1        7.410185\ndiagonal_width   28.52222  1        5.340620\n\n# We chose to go with a model which only includes `diagonal_length`, as this variable had the highest VIF value and therefore is able to best grasp the variance that is also measured by the other two length variables. However which strategy is most appropriate can differ per situation. We see now that the VIF values have returned to 'normal' values (although still a bit high).\n\n\nWhat happens with the regression model when there are more predictors than observations?\n\n\n# If there are more predictors than observations, the model can not be identified and the parameters cannot be estimated"
  },
  {
    "objectID": "labs/lab4_answers.html#exogenous-predictors",
    "href": "labs/lab4_answers.html#exogenous-predictors",
    "title": "Lab 4",
    "section": "Exogenous predictors",
    "text": "Exogenous predictors\nFor this assumption, the expected value of the errors (mean of the errors) must be 0. Furthermore, The errors must be independent of the predictors.\n\nWhat is the possible consequence of not meeting this assumption?\n\n\n# Not meeting this assumption results in biased estimates for the regression coefficients."
  },
  {
    "objectID": "labs/lab4_answers.html#constant-finite-error-variance",
    "href": "labs/lab4_answers.html#constant-finite-error-variance",
    "title": "Lab 4",
    "section": "Constant, finite error variance",
    "text": "Constant, finite error variance\nThis assumptions is also called ‘the assumption of homoscedasticity’. It states that the variance of the error terms should be constant over all levels of the predictors. This can be checked by plotting the residuals against the fitted values. These plots can be obtained by simply taking the first plot of a specified model, plot(model_x).\n\nCreate a residual vs fitted values plot for model_fish1, which is the first plot generated by the plot() function.\n\n\nmodel_fish1 %&gt;%\n  plot(1)\n\n\n\n\n\n\n\n\n\nLoad in the iris data, and specify a model where sepal length is predicted by all other variables and save this as model_iris1.\n\n\ndata_iris   &lt;- iris\nmodel_iris1 &lt;- lm(Sepal.Length ~ ., \n                  data = data_iris)\n\n\nCreate a residual vs fitted plot for this model as well.\n\n\nmodel_iris1 %&gt;%\n  plot(1)\n\n\n\n\n\n\n\n\n\nDiscuss both plots and indicate whether the assumption is met.\n\n\n# In the `iris_data` plot, it can be seen that the red line is quite constant. Also, the dots seem to have a rather constant variance. In the `fish_data` plot, however, the variance in error terms seems smaller for the lower values than for the higher values. This second plot indicates heteroscedasticity and indicates that the assumption is violated.\n\n\nDiscuss what the consequence would be if this assumption is violated.\n\n\n# If this assumption is violated, estimated standard errors are biased."
  },
  {
    "objectID": "labs/lab4_answers.html#independent-errors",
    "href": "labs/lab4_answers.html#independent-errors",
    "title": "Lab 4",
    "section": "Independent errors",
    "text": "Independent errors\nThis assumption states that error terms should have no correlation. Dependence of the errors can result from multiple things. First, there is a possible dependence in the error terms when there is serial dependence, for example because the data contains variables that are measured over time. Another reason can be when there is a cluster structure in the data, for example students in classes in schools.\n\nHow can both causes of correlated error terms be detected, and what can be done to solve the problem?\n\n\n# Temporal dependence can be checked by investigating the autocorrelation, while clustered data can be found by investigating the intra class correlation (ICC).\n\n# More important: dealing with these dependencies requires another model (multilevel for clustered data, or a model that account for the time aspect). Those models are out of the scope of this course, but always be aware of a theoretical dependency between your errors."
  },
  {
    "objectID": "labs/lab4_answers.html#normally-distributed-errors",
    "href": "labs/lab4_answers.html#normally-distributed-errors",
    "title": "Lab 4",
    "section": "Normally distributed errors",
    "text": "Normally distributed errors\nThis assumption states that errors should be roughly normally distributed. Like the assumption of homoscedasticity, this can be checked by model plots, provided by R.\n\nCreate a QQ plot for model_iris1, which is the second plot generated by the plot() function. Indicate whether the assumption is met.\n\n\nmodel_iris1 %&gt;%\n  plot(2)\n\n\n\n\n\n\n\n\n\nCreate a new model using the fish data, where diagonal_width is predicted by cross_length, and store the model as model_fish3.\n\n\nmodel_fish3 &lt;- lm(diagonal_width ~ cross_length, \n                  data = data_fish)\n\n\nCreate a QQ plot for model_fish3.\n\n\nmodel_fish3 %&gt;%\n  plot(2)\n\n\n\n\n\n\n\n\n\nInterpret the two plots. Is the assumption met in both cases?\n\n\n# In the two plots above, QQ plots are provided for the 2 models. For the first model, the error terms follow the ideal line pretty well, and the assumption holds. In the second plot, the tails deviate quite a lot from the intended line, and it can be debated that the assumption is violated.\n\n\nIn what cases is it problematic that the assumption is not met? And in what cases is it no problem?\n\n\n# The assumption is important in smaller samples (n &lt; 30). In bigger samples, violating the assumption is less of a big problem. For prediction intervals however, normality of errors is always wanted."
  },
  {
    "objectID": "labs/lab4_answers.html#outliers",
    "href": "labs/lab4_answers.html#outliers",
    "title": "Lab 4",
    "section": "Outliers",
    "text": "Outliers\nOutliers are observations that show extreme outcomes compared to the other data, or observations with outcome values that fit the model very badly. Outliers can be detected by inspecting the externally studentized residuals.\n\nMake a plot of studentized residuals by using the functions rstudent and plot for `model_fish1. What do you conclude?\n\n\nmodel_fish1 %&gt;%\n  rstudent() %&gt;%\n  plot()\n\n\n\n\n\n\n\n# There is at least one clear outlier around observation number 70.\n\n\nMake a plot of studentized residuals for model_iris1.\n\n\nmodel_iris1 %&gt;%\n  rstudent() %&gt;%\n  plot()\n\n\n\n\n\n\n\n\n\nStore the dataset Animals from the MASS package. Define a regression model where animals’ body weight is predicted by brain weight and store it as model_animals1.\n\n\ndata_animals   &lt;- Animals\nmodel_animals1 &lt;- lm(body ~ brain,\n                     data = data_animals)\n\n# There are not really any clear outliers to worry about.\n\n\nMake a plot of the studentized residuals for model_animals1.\n\n\nmodel_animals1 %&gt;%\n  rstudent() %&gt;%\n  plot()\n\n\n\n\n\n\n\n# Observation number 26 is an extreme outlier."
  },
  {
    "objectID": "labs/lab4_answers.html#high-leverage-observations",
    "href": "labs/lab4_answers.html#high-leverage-observations",
    "title": "Lab 4",
    "section": "High-leverage observations",
    "text": "High-leverage observations\nHigh-leverage observations are observations with extreme predictor values. To detect these observations, we look at their leverage values. These values can be summarized in a leverage plot.\n\nFor the model specified under model_animals1, create a leverage plot by plotting the hatvalues() of the model.\n\n\nmodel_animals1 %&gt;%\n  hatvalues() %&gt;%\n  plot()\n\n\n\n\n\n\n\n# In the leverage plot, observation 7 and 15 stand out from the other observations. When you look at the data set, you can notice that both of these observations are elephant species.\n\n# A case with high leverage is not necessarily bad: the influence on the model is more important."
  },
  {
    "objectID": "labs/lab4_answers.html#influence-on-the-model",
    "href": "labs/lab4_answers.html#influence-on-the-model",
    "title": "Lab 4",
    "section": "Influence on the model",
    "text": "Influence on the model\nBoth outliers and observations with high leverage are not necessarily a problem. Cases that are both, however, seem to form more of a problem. These cases can influence the model heavily and can therefore be problematic.\nInfluence measures come in two sorts: Cook’s distance checks for influential observations, while DFBETAS check for influential, and possible problematic, observations per regression coefficients.\n\nFor model_animals1, check Cooks distance by plotting the cooks.distance of the model.\n\n\nmodel_animals1 %&gt;%\n  cooks.distance() %&gt;%\n  plot()\n\n\n\n\n\n\n\n\n\nFor model_animals1, check the DFBETAS by using the function dfbetas.\n\n\nplot(dfbetas(model_animals1)[,1],\n     main = \"intercept\")\n\n\n\n\n\n\n\nplot(dfbetas(model_animals1)[,2],\n     main = \"slope\")\n\n\n\n\n\n\n\n# Note that because of the structure of the output of `dfbetas` it is not very convenient to process it using a pipe structure.\n\n\nDescribe what you see in the plots for Cook’s distance and DFBETAS. What do you conclude?\n\n\n# Case 26, the earlier spotted outlier, has in all three plots an outstanding value. There is reason to assume that this observation is problematic.\n\n\nDelete the problematic observation that you found in Question 12 and store the dataset under a new name.\n\n\ndata_animals2 &lt;- data_animals[-26,]\n\n\nFit the regression model where animals’ body weight is predicted by brain weight using the adjusted dataset and store it as model_animals2.\n\n\nmodel_animals2 &lt;- lm(body ~ brain, \n                     data = data_animals2)\n\n\nCompare the output to model_animals1 and describe the changes.\n\n\nsummary(model_animals1)\n\n\nCall:\nlm(formula = body ~ brain, data = data_animals)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -4316  -4312  -4242  -3806  82694 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) 4316.32258 3465.24131   1.246    0.224\nbrain         -0.06594    2.42114  -0.027    0.978\n\nResidual standard error: 16790 on 26 degrees of freedom\nMultiple R-squared:  2.853e-05, Adjusted R-squared:  -0.03843 \nF-statistic: 0.0007417 on 1 and 26 DF,  p-value: 0.9785\n\nsummary(model_animals2)\n\n\nCall:\nlm(formula = body ~ brain, data = data_animals2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1653.1  -876.8  -814.4  -778.9 10855.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) 810.1594   616.6065   1.314    0.201\nbrain         0.6855     0.4231   1.620    0.118\n\nResidual standard error: 2930 on 25 degrees of freedom\nMultiple R-squared:  0.09501,   Adjusted R-squared:  0.05881 \nF-statistic: 2.625 on 1 and 25 DF,  p-value: 0.1178\n\n# We see that the model changes quite a bit: the intercept becomes much lower, and the slope even changes direction (negative to positive).\n\n\nRun the plots for influential observations again on this new model and see if anything changes.\n\n\nmodel_animals2 %&gt;%\n  cooks.distance() %&gt;%\n  plot()\n\n\n\n\n\n\n\nplot(dfbetas(model_animals2)[,1],\n     main = \"intercept\")\n\n\n\n\n\n\n\nplot(dfbetas(model_animals2)[,2],\n     main = \"slope\")\n\n\n\n\n\n\n\n# We see that new influential observations arise. These were earlier overshadowed by observation 26. If you look at these cases, you see these are the cases with very heavy animals. In this case the solution should be to transform the data and take the log of the weights, instead of these values. This means that the assumption of linearity was probably not met for this data set.*"
  },
  {
    "objectID": "labs/lab5.html",
    "href": "labs/lab5.html",
    "title": "Lab 5",
    "section": "",
    "text": "We will use the following packages in this practical:\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(foreign)\nlibrary(kableExtra)\nlibrary(janitor)\nlibrary(readr)\nIn this practical, you will perform regression analyses using glm() and inspect variables by plotting these variables, using ggplot()."
  },
  {
    "objectID": "labs/lab5.html#working-with-odds-and-log-odds",
    "href": "labs/lab5.html#working-with-odds-and-log-odds",
    "title": "Lab 5",
    "section": "Working with odds and log-odds",
    "text": "Working with odds and log-odds\nBefore we get started with logistic modelling it helps to understand how odds, log-odds, and probability are related. Essentially, they are all just different expressions of the same thing and converting between them involve simple formulas.\nCoefficients calculated using the glm() function returns log-odds by default. Most of us find it difficult to think in terms of log-odds, so instead we convert them to odds (or odds-ratios) using the exp() function. If we want to go from odds to log-odds, we just take the logarithm using log().\nAn odds-ratio is the probability of success and is defined as \\(Odds = \\frac{P}{1-P}\\), where \\(P\\) is the probability of an event happening and \\(1-P\\) is the probability that it does not happen. For example, if we have an 80% chance of a sunny day, then we have a 20% chance of a rainy day. The odds would then equal \\(\\frac{.80}{.20} = 4\\), meaning the odds of a sunny day are 4 to 1. Let’s consider this further with an example.\nThe code below creates a data frame called data with a column called conc showing the number of trials wherein different concentrations of the peptide-C protein inhibited the flow of current across a membrane. The yes column contains counts of trials where this occured.\n\ndata &lt;- data.frame(conc = c(0.1, 0.5, 1, 10, 20, 30, 50, 70, 80, 100, 150),\n                   no = c(7, 1, 10, 9, 2, 9, 13, 1, 1, 4, 3),\n                   yes = c(0, 0, 3, 4, 0, 6, 7, 0, 0, 1 ,7)\n                   ) \ndata\n\n    conc no yes\n1    0.1  7   0\n2    0.5  1   0\n3    1.0 10   3\n4   10.0  9   4\n5   20.0  2   0\n6   30.0  9   6\n7   50.0 13   7\n8   70.0  1   0\n9   80.0  1   0\n10 100.0  4   1\n11 150.0  3   7\n\n\n\nAdd the following variables to the dataset:\n\n\nthe total number of trials for each observation (i.e., the sum of the no and yes trials for each row)\nthe proportion of yes trials in each row (i.e. yes divided by the total)\nthe log-odds of inhibition for each row (i.e. the log-odds of yes vs no)\n\n\nInspect the new columns. Do you notice anything unusual?\nAdd a new column to your dataset containing the corrected odds.\n\nYou can compute the value of this column using the following formulation of the log-odds:\n\\[ log(odds) = log(\\frac{yes + 0.5} {no + 0.5}) \\]\n\nFit a logistic regression model where:\n\n\nprop is the outcome\nconc is the only predictor\nthe number of total trials per row are used as weights (we need this because a different number of trials can go into defining each observation of prop)\n\nInterpret the slope estimate."
  },
  {
    "objectID": "labs/lab5.html#titanic-data",
    "href": "labs/lab5.html#titanic-data",
    "title": "Lab 5",
    "section": "Titanic data",
    "text": "Titanic data\nYou will work with the titanic data set which you can find in the surfdrive folder, containing information on the fate of passengers on the infamous voyage.\n\nSurvived: this is the outcome variable that you are trying to predict, with 1 meaning a passenger survived and 0 meaning they did not\nPclass: this is the ticket class the passenger was travelling on, with 1, 2, and 3 representing 1st, 2nd and 3rd class respectively\nAge: this is the age of the passenger in years\nSex: this is the sex of the passenger, either male or female\n\n\nRead in the data from the “titanic.csv” file, selecting only the variables Survived, Pclass, Sex and Age. If necessary, correct the class of the variables.\nWhat relationships do you expect to find between the predictor variables and the outcome?\nInvestigate how many passengers survived in each class. You can do this visually by creating a bar plot, or by using the table() function. Search ??table for more information.\nSimilarly, investigate the relationship between survival and sex by creating a bar plot and a table.\nInvestigate the relationship between age and survival by creating a histogram of the age of survivors versus non-survivors."
  },
  {
    "objectID": "labs/lab5.html#no-predictors",
    "href": "labs/lab5.html#no-predictors",
    "title": "Lab 5",
    "section": "No predictors",
    "text": "No predictors\n\nSpecify a logistic regression model where “Survived” is the outcome and there are no predictors."
  },
  {
    "objectID": "labs/lab5.html#binary-predictor",
    "href": "labs/lab5.html#binary-predictor",
    "title": "Lab 5",
    "section": "Binary predictor",
    "text": "Binary predictor\n\nSpecify a logistic regression model where “Survived” is the outcome and “Sex” is the only predictor.\nWhat does the intercept mean? What are the odds and what are the log-odds of survival for males?"
  },
  {
    "objectID": "labs/lab5.html#categorical-predictor-more-than-2-categories",
    "href": "labs/lab5.html#categorical-predictor-more-than-2-categories",
    "title": "Lab 5",
    "section": "Categorical predictor (more than 2 categories)",
    "text": "Categorical predictor (more than 2 categories)\n\nSpecify a logistic regression model where “Survived” is the outcome and “Pclass” is the only predictor.\nWhich category is the reference group? What are their odds of survival?\nWhat are the chances of survival for 2nd and 3rd class passengers?"
  },
  {
    "objectID": "labs/lab5.html#continuous-predictor",
    "href": "labs/lab5.html#continuous-predictor",
    "title": "Lab 5",
    "section": "Continuous predictor",
    "text": "Continuous predictor\n\nSpecify a logistic regression model where “Survived” is the outcome and “Age” is the only predictor.\n\nSave this model as you will come back to it later.\n\nWhat does the intercept mean when there is a continuous predictor?\nHow are the odds and log-odds interpreted for a continuous predictor?"
  },
  {
    "objectID": "labs/lab5.html#multinomial-model-with-an-interaction-term",
    "href": "labs/lab5.html#multinomial-model-with-an-interaction-term",
    "title": "Lab 5",
    "section": "Multinomial model with an interaction term",
    "text": "Multinomial model with an interaction term\n\nSpecify a logistic regression model Survived is the outcome and Pclass plus an interaction between Sex and Age as the predictor.\n\nSave this model as we will return to it later.\n\nHow is the significant interaction term interpreted in this model?"
  },
  {
    "objectID": "labs/lab5.html#deviance",
    "href": "labs/lab5.html#deviance",
    "title": "Lab 5",
    "section": "Deviance",
    "text": "Deviance\nDeviance is measure of the goodness-of-fit in a GLM where lower deviance indicates a better fitting model. R reports two types of deviance:\n\nnull deviance: how well the outcome is predicted by the intercept-only model\nresidual deviance: how well the outcome is predicted by the model with the predictors added\n\n\nGet the model summaries and indicate what the null and residual deviance are.\n\nWe can use the anova() function to perform an analysis of deviance that compares the difference in deviances between competing models.\n\nCompare the fit of model 1 with the fit of model 2 using anova() andtest = “Chisq”`."
  },
  {
    "objectID": "labs/lab5.html#information-criteria",
    "href": "labs/lab5.html#information-criteria",
    "title": "Lab 5",
    "section": "Information criteria",
    "text": "Information criteria\nAIC is the Akaike’s Information Criterion, a method for assessing model quality through comparison of related models. AIC is based on the deviance but introduces a penalty for more complex models. The number itself is not meaninful, and it is only useful when comparing models against one another. Like deviance, the model with the lowest AIC is best.\n\nUse the AIC() function to get the AIC value for model 1 and model 2.\n\nBIC is the Bayesian Information Criterion and is very similar to AIC, but penalises a complex model more than the AIC would. Complex models will have a larger score indicating worse fit. One difference to the AIC is that the probability of selecting the correct model with the BIC increases as the sample size of the training set increases.\n\nUse the BIC() function to get the BIC value for model 1 and model 2.\nWhich model should we proceed with?"
  },
  {
    "objectID": "labs/lab5_answers.html",
    "href": "labs/lab5_answers.html",
    "title": "Lab 5",
    "section": "",
    "text": "We will use the following packages in this practical:\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(foreign)\nlibrary(kableExtra)\nlibrary(janitor)\nlibrary(readr)\nIn this practical, you will perform regression analyses using glm() and inspect variables by plotting these variables, using ggplot()."
  },
  {
    "objectID": "labs/lab5_answers.html#working-with-odds-and-log-odds",
    "href": "labs/lab5_answers.html#working-with-odds-and-log-odds",
    "title": "Lab 5",
    "section": "Working with odds and log-odds",
    "text": "Working with odds and log-odds\nBefore we get started with logistic modelling it helps to understand how odds, log-odds, and probability are related. Essentially, they are all just different expressions of the same thing and converting between them involve simple formulas.\nCoefficients calculated using the glm() function returns log-odds by default. Most of us find it difficult to think in terms of log-odds, so instead we convert them to odds (or odds-ratios) using the exp() function. If we want to go from odds to log-odds, we just take the logarithm using log().\nAn odds-ratio is the probability of success and is defined as \\(Odds = \\frac{P}{1-P}\\), where \\(P\\) is the probability of an event happening and \\(1-P\\) is the probability that it does not happen. For example, if we have an 80% chance of a sunny day, then we have a 20% chance of a rainy day. The odds would then equal \\(\\frac{.80}{.20} = 4\\), meaning the odds of a sunny day are 4 to 1. Let’s consider this further with an example.\nThe code below creates a data frame called data with a column called conc showing the number of trials wherein different concentrations of the peptide-C protein inhibited the flow of current across a membrane. The yes column contains counts of trials where this occured.\n\ndata &lt;- data.frame(conc = c(0.1, 0.5, 1, 10, 20, 30, 50, 70, 80, 100, 150),\n                   no = c(7, 1, 10, 9, 2, 9, 13, 1, 1, 4, 3),\n                   yes = c(0, 0, 3, 4, 0, 6, 7, 0, 0, 1 ,7)\n                   ) \ndata\n\n    conc no yes\n1    0.1  7   0\n2    0.5  1   0\n3    1.0 10   3\n4   10.0  9   4\n5   20.0  2   0\n6   30.0  9   6\n7   50.0 13   7\n8   70.0  1   0\n9   80.0  1   0\n10 100.0  4   1\n11 150.0  3   7\n\n\n\nAdd the following variables to the dataset:\n\n\nthe total number of trials for each observation (i.e., the sum of the no and yes trials for each row)\nthe proportion of yes trials in each row (i.e. yes divided by the total)\nthe log-odds of inhibition for each row (i.e. the log-odds of yes vs no)\n\n\ndata &lt;- \n  data %&gt;% \n  mutate(total = no + yes,\n         prop = yes / total,\n         logit = qlogis(prop)\n         )\n\n# The `qlogis()` function is equivalent to the log-odds (i.e, logit) function.\n\n\nInspect the new columns. Do you notice anything unusual?\n\n\nhead(data)\n\n  conc no yes total      prop      logit\n1  0.1  7   0     7 0.0000000       -Inf\n2  0.5  1   0     1 0.0000000       -Inf\n3  1.0 10   3    13 0.2307692 -1.2039728\n4 10.0  9   4    13 0.3076923 -0.8109302\n5 20.0  2   0     2 0.0000000       -Inf\n6 30.0  9   6    15 0.4000000 -0.4054651\n\n#There are many zero proportions which produce logit values of infinity. We can work around this issue by adding a constant (usually 0.5) to all cells before calculating the log-odds. We add the same value to the numerator and denominator of our odds formula, so we don't change the relative interpretations of the odds. We could also add a 1 to each cell. This option is conceptually interesting because the log of 1 equals 0. It's almost like we're adding zero to the odds and still correcting the issue.\n\n\nAdd a new column to your dataset containing the corrected odds.\n\nYou can compute the value of this column using the following formulation of the log-odds:\n\\[ log(odds) = log(\\frac{yes + 0.5} {no + 0.5}) \\]\n\nrobustLogit &lt;- function(x, y) log((x + 0.5) / (y + 0.5))\n\ndata &lt;- data %&gt;% \n  mutate(logit2 = robustLogit(yes, no))\n\ndata\n\n    conc no yes total      prop      logit     logit2\n1    0.1  7   0     7 0.0000000       -Inf -2.7080502\n2    0.5  1   0     1 0.0000000       -Inf -1.0986123\n3    1.0 10   3    13 0.2307692 -1.2039728 -1.0986123\n4   10.0  9   4    13 0.3076923 -0.8109302 -0.7472144\n5   20.0  2   0     2 0.0000000       -Inf -1.6094379\n6   30.0  9   6    15 0.4000000 -0.4054651 -0.3794896\n7   50.0 13   7    20 0.3500000 -0.6190392 -0.5877867\n8   70.0  1   0     1 0.0000000       -Inf -1.0986123\n9   80.0  1   0     1 0.0000000       -Inf -1.0986123\n10 100.0  4   1     5 0.2000000 -1.3862944 -1.0986123\n11 150.0  3   7    10 0.7000000  0.8472979  0.7621401\n\n\n\nFit a logistic regression model where:\n\n\nprop is the outcome\nconc is the only predictor\nthe number of total trials per row are used as weights (we need this because a different number of trials can go into defining each observation of prop)\n\nInterpret the slope estimate.\n\nsummary(glm(prop ~ conc, \n            family = binomial, \n            weights = total, \n            data = data))\n\n\nCall:\nglm(formula = prop ~ conc, family = binomial, data = data, weights = total)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.32701    0.33837  -3.922 8.79e-05 ***\nconc         0.01215    0.00496   2.450   0.0143 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 16.683  on 10  degrees of freedom\nResidual deviance: 10.389  on  9  degrees of freedom\nAIC: 30.988\n\nNumber of Fisher Scoring iterations: 4\n\n# A unit increase in conc increases the log-odds of inhibition by 0.0121 units, and this increase is statistically significant.\n\n# If we exponentiate the slope estimate, we can get an interpretation in odds units, but the effect becomes multiplicative instead of additive. So for every unit increase in conc, the odds of inhibition are 1.01215 times higher. Note then that odds above 1 indicate inhibition is x-times higher, while odds below 1 indicate inhibition is x-times less."
  },
  {
    "objectID": "labs/lab5_answers.html#titanic-data",
    "href": "labs/lab5_answers.html#titanic-data",
    "title": "Lab 5",
    "section": "Titanic data",
    "text": "Titanic data\nYou will work with the titanic data set which you can find in the surfdrive folder, containing information on the fate of passengers on the infamous voyage.\n\nSurvived: this is the outcome variable that you are trying to predict, with 1 meaning a passenger survived and 0 meaning they did not\nPclass: this is the ticket class the passenger was travelling on, with 1, 2, and 3 representing 1st, 2nd and 3rd class respectively\nAge: this is the age of the passenger in years\nSex: this is the sex of the passenger, either male or female\n\n\nRead in the data from the “titanic.csv” file, selecting only the variables Survived, Pclass, Sex and Age. If necessary, correct the class of the variables.\n\n\ntitanic &lt;- read_csv(\"titanic.csv\") %&gt;% \n  mutate(Survived = as.factor(Survived),\n         Sex = as.factor(Sex),\n         Pclass = as.factor(Pclass))\n\nRows: 891 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Sex\ndbl (3): Survived, Pclass, Age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nWhat relationships do you expect to find between the predictor variables and the outcome?\n\n\n# We could say that:\n# class is related to the outcome as passengers travelling on a higher class ticket have a higher probability of survival\n# sex is related to the outcome as women have a higher probability of survival\n# age is related to the outcome as younger passengers have a higher probability of survival\n\n\nInvestigate how many passengers survived in each class. You can do this visually by creating a bar plot, or by using the table() function. Search ??table for more information.\n\n\ntitanic %&gt;% \n  ggplot(aes(Pclass, fill = Survived)) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"Passenger Class\",\n       y = \"Count\") +\n  theme_bw()\n\n\n\n\n\n\n\n# The bar plot clearly shows that people in lower class were less likely to survive.\n# We can also use the `prop.table()` function to investigate this. The argument `margin = 1` turns the counts to marginal proportions.\n\ntitanic %$% \n  table(Pclass, Survived) %&gt;% \n  prop.table(margin = 1) %&gt;% \n  round(2)\n\n      Survived\nPclass    0    1\n     1 0.37 0.63\n     2 0.53 0.47\n     3 0.76 0.24\n\n\n\nSimilarly, investigate the relationship between survival and sex by creating a bar plot and a table.\n\n\ntitanic %$% \n  table(Sex, Survived) %&gt;% \n  prop.table(margin = 1) %&gt;% \n  round(2)\n\n        Survived\nSex         0    1\n  female 0.26 0.74\n  male   0.81 0.19\n\n# The table shows the proportion of males and females that survived versus those who did not survive. Females are much more likely to have survived than males.\n\ntitanic %&gt;% \n  ggplot(aes(Sex, fill = Survived)) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"Sex\",\n       y = \"Count\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nInvestigate the relationship between age and survival by creating a histogram of the age of survivors versus non-survivors.\n\n\ntitanic %&gt;% \n  ggplot(aes(Age, fill = Survived)) +\n  geom_histogram(colour = \"white\") +\n  labs(x = \"Age\",\n       y = \"Count\") +\n  facet_wrap(~Survived) +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n# The distribution of age is different for survivors and non-survivors. Younger passengers have higher chances of survival compared to older passengers."
  },
  {
    "objectID": "labs/lab5_answers.html#no-predictors",
    "href": "labs/lab5_answers.html#no-predictors",
    "title": "Lab 5",
    "section": "No predictors",
    "text": "No predictors\n\nSpecify a logistic regression model where “Survived” is the outcome and there are no predictors.\n\n\nglm(Survived ~ 1, \n    family = binomial, \n    data = titanic) %&gt;% \n  summary()\n\n\nCall:\nglm(formula = Survived ~ 1, family = binomial, data = titanic)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.47329    0.06889   -6.87  6.4e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1186.7  on 890  degrees of freedom\nResidual deviance: 1186.7  on 890  degrees of freedom\nAIC: 1188.7\n\nNumber of Fisher Scoring iterations: 4\n\n# A logistic regression without any predictors is simply modelling the log-odds of survival for the entire population (the intercept, beta0).\n# The log-odds are -0.473, and the odds are $exp(-0.473) = 0.623$.\n\n# We can also get the odds from a frequency table: the probability of survival is $342/549 = 0.623$. The log-odds equals exp(beta0) = -0.473.\n\ntitanic %&gt;% \n  count(Survived) %&gt;% \n  mutate(prop = prop.table(n)) %&gt;% \n  kbl(digits = 2) %&gt;% \n  kable_paper(bootstrap_options = \"striped\", full_width = FALSE)\n\n\n\n\nSurvived\nn\nprop\n\n\n\n\n0\n549\n0.62\n\n\n1\n342\n0.38"
  },
  {
    "objectID": "labs/lab5_answers.html#binary-predictor",
    "href": "labs/lab5_answers.html#binary-predictor",
    "title": "Lab 5",
    "section": "Binary predictor",
    "text": "Binary predictor\n\nSpecify a logistic regression model where “Survived” is the outcome and “Sex” is the only predictor.\n\n\nglm(Survived ~ Sex, \n    family = binomial, \n    data = titanic) %&gt;% \n  summary()\n\n\nCall:\nglm(formula = Survived ~ Sex, family = binomial, data = titanic)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.0566     0.1290   8.191 2.58e-16 ***\nSexmale      -2.5137     0.1672 -15.036  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1186.7  on 890  degrees of freedom\nResidual deviance:  917.8  on 889  degrees of freedom\nAIC: 921.8\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nWhat does the intercept mean? What are the odds and what are the log-odds of survival for males?\n\n\n# In the model with one dichotomous predictor we are modelling logit(p) = beta0 + beta1*male.\n\n# The intercept is the log-odds of survival for women (1.0566), since the reference group is female.\n\n# The log-odds of survival for men is -2.5137 lower than for women. The odds of survival for men is 0.081, or 92% lower than females."
  },
  {
    "objectID": "labs/lab5_answers.html#categorical-predictor-more-than-2-categories",
    "href": "labs/lab5_answers.html#categorical-predictor-more-than-2-categories",
    "title": "Lab 5",
    "section": "Categorical predictor (more than 2 categories)",
    "text": "Categorical predictor (more than 2 categories)\n\nSpecify a logistic regression model where “Survived” is the outcome and “Pclass” is the only predictor.\n\n\nglm(Survived ~ Pclass, \n    family = binomial, \n    data = titanic) %&gt;% \n  summary()\n\n\nCall:\nglm(formula = Survived ~ Pclass, family = binomial, data = titanic)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.5306     0.1409   3.766 0.000166 ***\nPclass2      -0.6394     0.2041  -3.133 0.001731 ** \nPclass3      -1.6704     0.1759  -9.496  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1186.7  on 890  degrees of freedom\nResidual deviance: 1083.1  on 888  degrees of freedom\nAIC: 1089.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nWhich category is the reference group? What are their odds of survival?\n\n\n# The reference group are 1st class passengers, represented by the intercept.\n# The log-odds of survival for 1st class passengers is 0.5306.\n# The odds are 1.70, meaning 1st class passengers are 70% more likely to survive.\n\n\nWhat are the chances of survival for 2nd and 3rd class passengers?\n\n\n# For 2nd class passengers, the log-odds of survival is -0.6394.\n# The odds are  0.527, meaning 2nd class passengers are 47% less likely to survive than 1st class passengers.\n\n# For 3rd class passengers, the log-odds of survival is -1.646.\n# The odds are 0.188, meaning 3nd class passengers are 81% less likely to survive than 1st class passengers."
  },
  {
    "objectID": "labs/lab5_answers.html#continuous-predictor",
    "href": "labs/lab5_answers.html#continuous-predictor",
    "title": "Lab 5",
    "section": "Continuous predictor",
    "text": "Continuous predictor\n\nSpecify a logistic regression model where “Survived” is the outcome and “Age” is the only predictor.\n\nSave this model as you will come back to it later.\n\nfit1 &lt;- glm(Survived ~ Age, \n            family = binomial, \n            data = titanic)\nsummary(fit1)\n\n\nCall:\nglm(formula = Survived ~ Age, family = binomial, data = titanic)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -0.14327    0.17209  -0.832   0.4051  \nAge         -0.01120    0.00539  -2.077   0.0378 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1186.7  on 890  degrees of freedom\nResidual deviance: 1182.3  on 889  degrees of freedom\nAIC: 1186.3\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nWhat does the intercept mean when there is a continuous predictor?\n\n\n# In the case of a continuous predictor there is no real reference group. Instead, the intercept is the log-odds of survival when age = 0. In this model, the log-odds of survival for passengers of age 0 is -0.143, corresponding with the odds of survival at 0.867 (= exp(log odds)).\n\n\nHow are the odds and log-odds interpreted for a continuous predictor?\n\n\n# For continuous predictors, the log-odds either increase or decrease with every unit increase in the continuous predictor. So, in our model:\n# For every increase in age of one year, the log-odds of survival decrease by -0.011, meaning that as age increases the chances of survival decrease.\n# For every increase in age of one year, the odds of survival are 0.99 (= exp(-0.0112)) times the odds of those with one age unit less, or -1.09%."
  },
  {
    "objectID": "labs/lab5_answers.html#multinomial-model-with-an-interaction-term",
    "href": "labs/lab5_answers.html#multinomial-model-with-an-interaction-term",
    "title": "Lab 5",
    "section": "Multinomial model with an interaction term",
    "text": "Multinomial model with an interaction term\n\nSpecify a logistic regression model Survived is the outcome and Pclass plus an interaction between Sex and Age as the predictor.\n\nSave this model as we will return to it later.\n\nfit2 &lt;- glm(Survived ~ Pclass + Sex*Age, family = binomial, data = titanic)\nsummary(fit2)\n\n\nCall:\nglm(formula = Survived ~ Pclass + Sex * Age, family = binomial, \n    data = titanic)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.834344   0.414982   6.830 8.49e-12 ***\nPclass2     -1.264399   0.273220  -4.628 3.70e-06 ***\nPclass3     -2.412614   0.250004  -9.650  &lt; 2e-16 ***\nSexmale     -1.262875   0.433364  -2.914 0.003567 ** \nAge         -0.004202   0.011426  -0.368 0.713083    \nSexmale:Age -0.048460   0.014576  -3.325 0.000885 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1186.66  on 890  degrees of freedom\nResidual deviance:  793.82  on 885  degrees of freedom\nAIC: 805.82\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nHow is the significant interaction term interpreted in this model?\n\n\n# The interaction between age and sex is significant, suggesting the slopes for age on survival are different for males and females."
  },
  {
    "objectID": "labs/lab5_answers.html#deviance",
    "href": "labs/lab5_answers.html#deviance",
    "title": "Lab 5",
    "section": "Deviance",
    "text": "Deviance\nDeviance is measure of the goodness-of-fit in a GLM where lower deviance indicates a better fitting model. R reports two types of deviance:\n\nnull deviance: how well the outcome is predicted by the intercept-only model\nresidual deviance: how well the outcome is predicted by the model with the predictors added\n\n\nGet the model summaries and indicate what the null and residual deviance are.\n\n\n# You can use the `summary()` command to get the deviance statistics for each model. The null and residual deviance are below the model coefficients. \n\nsummary(fit1)\n\n\nCall:\nglm(formula = Survived ~ Age, family = binomial, data = titanic)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -0.14327    0.17209  -0.832   0.4051  \nAge         -0.01120    0.00539  -2.077   0.0378 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1186.7  on 890  degrees of freedom\nResidual deviance: 1182.3  on 889  degrees of freedom\nAIC: 1186.3\n\nNumber of Fisher Scoring iterations: 4\n\nsummary(fit2)\n\n\nCall:\nglm(formula = Survived ~ Pclass + Sex * Age, family = binomial, \n    data = titanic)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.834344   0.414982   6.830 8.49e-12 ***\nPclass2     -1.264399   0.273220  -4.628 3.70e-06 ***\nPclass3     -2.412614   0.250004  -9.650  &lt; 2e-16 ***\nSexmale     -1.262875   0.433364  -2.914 0.003567 ** \nAge         -0.004202   0.011426  -0.368 0.713083    \nSexmale:Age -0.048460   0.014576  -3.325 0.000885 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1186.66  on 890  degrees of freedom\nResidual deviance:  793.82  on 885  degrees of freedom\nAIC: 805.82\n\nNumber of Fisher Scoring iterations: 5\n\n# For model 1, the null deviance is 1186.7 and the residual deviance is 1182.3 For model 2, the null deviance is 1186.66 and the residual deviance is 793.82\n\nWe can use the anova() function to perform an analysis of deviance that compares the difference in deviances between competing models.\n\nCompare the fit of model 1 with the fit of model 2 using anova() andtest = “Chisq”`.\n\n\nanova(fit1, fit2, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: Survived ~ Age\nModel 2: Survived ~ Pclass + Sex * Age\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1       889    1182.28                          \n2       885     793.82  4   388.45 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# The analysis of deviance indicates that there is a reduction in residual deviance of 388.46 that is statistically significant. Model 2 is a better model. For a binomial model, the statistical test should be the chi-square difference test."
  },
  {
    "objectID": "labs/lab5_answers.html#information-criteria",
    "href": "labs/lab5_answers.html#information-criteria",
    "title": "Lab 5",
    "section": "Information criteria",
    "text": "Information criteria\nAIC is the Akaike’s Information Criterion, a method for assessing model quality through comparison of related models. AIC is based on the deviance but introduces a penalty for more complex models. The number itself is not meaninful, and it is only useful when comparing models against one another. Like deviance, the model with the lowest AIC is best.\n\nUse the AIC() function to get the AIC value for model 1 and model 2.\n\n\nAIC(fit1, fit2)\n\n     df       AIC\nfit1  2 1186.2782\nfit2  6  805.8245\n\n# The AIC for model 2 is lower than the AIC for model 1, indicating that model 2 has a better fit\n\nBIC is the Bayesian Information Criterion and is very similar to AIC, but penalises a complex model more than the AIC would. Complex models will have a larger score indicating worse fit. One difference to the AIC is that the probability of selecting the correct model with the BIC increases as the sample size of the training set increases.\n\nUse the BIC() function to get the BIC value for model 1 and model 2.\n\n\nBIC(fit1, fit2)\n\n     df       BIC\nfit1  2 1195.8629\nfit2  6  834.5785\n\n# The BIC for model 2 is lower than the BIC for model 1, indicating that model 2 has a better fit\n\n\nWhich model should we proceed with?\n\n\n# Model 2, as it has lower residual deviance, AIC and BIC."
  },
  {
    "objectID": "labs/lab4.html",
    "href": "labs/lab4.html",
    "title": "Lab 4",
    "section": "",
    "text": "In this practical, the assumptions of the linear regression model will be discussed. You will practice with checking the different assumptions, and practice with accounting for some of the assumptions with additional steps. Please note that these assumptions can only be checked once you have selected a (final) model, as these assumptions ‘need’ a model that they apply to.\nWe will use the following packages in this practical:\n\nlibrary(magrittr)\nlibrary(ggplot2) \nlibrary(regclass)\nlibrary(MASS)"
  },
  {
    "objectID": "labs/lab4.html#linearity",
    "href": "labs/lab4.html#linearity",
    "title": "Lab 4",
    "section": "Linearity",
    "text": "Linearity\nWith the assumption of linearity, it is assumed that the relation between the dependent and independent variables is (more or less) linear. You can check this by generating a scatterplot using a predictor variable and outcome variable of the regression model.\n\nCheck whether there is a linear relation between the variables vertical length and the cross length.\nNext check the relation between weight and height.\nDescribe both plots. What differences do you see?\n\nWhen a non-linear relation is present, you can either choose another model to use, or transform the predictor before adding it to the model, for example using a log-transformation. Applying a transformation, however, will not always solve the problem, and makes interpretation of the model less intuitive.\n\nApply a log-transformation to the weight variable.\nPlot the relation between length and weight again, but now including the transformed variable.\nDescribe if the transformation improved the linear relation."
  },
  {
    "objectID": "labs/lab4.html#predictor-matrix-full-rank",
    "href": "labs/lab4.html#predictor-matrix-full-rank",
    "title": "Lab 4",
    "section": "Predictor matrix full rank",
    "text": "Predictor matrix full rank\nThis assumption states that:\n\nthere need to be more observations than predictors (n &gt; P).\n\nno predictor can be a linear combination of other predictors; predictors cannot have a very high correlation (multicollinearity).\n\n\nThe first part of this assumption is easy to check: see if the number of observations minus the number of predictors is a positive number. The second part can be checked by either obtaining correlations between the predictors, or by determining the VIF (variance inflation factor). When the VIF is above 10, this indicate high multicollinearity. To account for this, predictors can be excluded from the model, or a new variable can be constructed based on predictors with a high correlation.\nTo examine VIF scores, the function VIF() from the regclass can be used on a prespecified model. If this model includes a categorical variable with multiple categories, such as ‘species’ in the example data, the generalized VIF is used, and we have to look at the third column (GVIF^*(1/(2*Df))), these values can be compared to normal VIF values.\n\nSpecify a linear model with weight as outcome variable using all other variables in the dataset as predictors. Save this model as model_fish1. Calculate VIF values for this model.\nCheck the VIF scores. If VIF scores exceed a score of 10, give substantial explanation why the VIF scores are this high.\nWhat adjustments can be made to the model to account for multicollinearity in this case?\nRun a new model which only includes one of the three length variables and call it model_fish2. Describe if there is an improvement.\nWhat happens with the regression model when there are more predictors than observations?"
  },
  {
    "objectID": "labs/lab4.html#exogenous-predictors",
    "href": "labs/lab4.html#exogenous-predictors",
    "title": "Lab 4",
    "section": "Exogenous predictors",
    "text": "Exogenous predictors\nFor this assumption, the expected value of the errors (mean of the errors) must be 0. Furthermore, The errors must be independent of the predictors.\n\nWhat is the possible consequence of not meeting this assumption?"
  },
  {
    "objectID": "labs/lab4.html#constant-finite-error-variance",
    "href": "labs/lab4.html#constant-finite-error-variance",
    "title": "Lab 4",
    "section": "Constant, finite error variance",
    "text": "Constant, finite error variance\nThis assumptions is also called ‘the assumption of homoscedasticity’. It states that the variance of the error terms should be constant over all levels of the predictors. This can be checked by plotting the residuals against the fitted values. These plots can be obtained by simply taking the first plot of a specified model, plot(model_x).\n\nCreate a residual vs fitted values plot for model_fish1, which is the first plot generated by the plot() function.\nLoad in the iris data, and specify a model where sepal length is predicted by all other variables and save this as model_iris1.\nCreate a residual vs fitted plot for this model as well.\nDiscuss both plots and indicate whether the assumption is met.\nDiscuss what the consequence would be if this assumption is violated."
  },
  {
    "objectID": "labs/lab4.html#independent-errors",
    "href": "labs/lab4.html#independent-errors",
    "title": "Lab 4",
    "section": "Independent errors",
    "text": "Independent errors\nThis assumption states that error terms should have no correlation. Dependence of the errors can result from multiple things. First, there is a possible dependence in the error terms when there is serial dependence, for example because the data contains variables that are measured over time. Another reason can be when there is a cluster structure in the data, for example students in classes in schools.\n\nHow can both causes of correlated error terms be detected, and what can be done to solve the problem?"
  },
  {
    "objectID": "labs/lab4.html#normally-distributed-errors",
    "href": "labs/lab4.html#normally-distributed-errors",
    "title": "Lab 4",
    "section": "Normally distributed errors",
    "text": "Normally distributed errors\nThis assumption states that errors should be roughly normally distributed. Like the assumption of homoscedasticity, this can be checked by model plots, provided by R.\n\nCreate a QQ plot for model_iris1, which is the second plot generated by the plot() function. Indicate whether the assumption is met.\nCreate a new model using the fish data, where diagonal_width is predicted by cross_length, and store the model as model_fish3.\nCreate a QQ plot for model_fish3.\nInterpret the two plots. Is the assumption met in both cases?\nIn what cases is it problematic that the assumption is not met? And in what cases is it no problem?"
  },
  {
    "objectID": "labs/lab4.html#outliers",
    "href": "labs/lab4.html#outliers",
    "title": "Lab 4",
    "section": "Outliers",
    "text": "Outliers\nOutliers are observations that show extreme outcomes compared to the other data, or observations with outcome values that fit the model very badly. Outliers can be detected by inspecting the externally studentized residuals.\n\nMake a plot of studentized residuals by using the functions rstudent and plot for `model_fish1. What do you conclude?\nMake a plot of studentized residuals for model_iris1.\nStore the dataset Animals from the MASS package. Define a regression model where animals’ body weight is predicted by brain weight and store it as model_animals1.\nMake a plot of the studentized residuals for model_animals1."
  },
  {
    "objectID": "labs/lab4.html#high-leverage-observations",
    "href": "labs/lab4.html#high-leverage-observations",
    "title": "Lab 4",
    "section": "High-leverage observations",
    "text": "High-leverage observations\nHigh-leverage observations are observations with extreme predictor values. To detect these observations, we look at their leverage values. These values can be summarized in a leverage plot.\n\nFor the model specified under model_animals1, create a leverage plot by plotting the hatvalues() of the model."
  },
  {
    "objectID": "labs/lab4.html#influence-on-the-model",
    "href": "labs/lab4.html#influence-on-the-model",
    "title": "Lab 4",
    "section": "Influence on the model",
    "text": "Influence on the model\nBoth outliers and observations with high leverage are not necessarily a problem. Cases that are both, however, seem to form more of a problem. These cases can influence the model heavily and can therefore be problematic.\nInfluence measures come in two sorts: Cook’s distance checks for influential observations, while DFBETAS check for influential, and possible problematic, observations per regression coefficients.\n\nFor model_animals1, check Cooks distance by plotting the cooks.distance of the model.\nFor model_animals1, check the DFBETAS by using the function dfbetas.\nDescribe what you see in the plots for Cook’s distance and DFBETAS. What do you conclude?\nDelete the problematic observation that you found in Question 12 and store the dataset under a new name.\nFit the regression model where animals’ body weight is predicted by brain weight using the adjusted dataset and store it as model_animals2.\nCompare the output to model_animals1 and describe the changes.\nRun the plots for influential observations again on this new model and see if anything changes."
  },
  {
    "objectID": "labs/lab6.html",
    "href": "labs/lab6.html",
    "title": "Lab 6",
    "section": "",
    "text": "We will use the following packages in this practical:\n\ndplyr for manipulation\nmagrittr for piping\nreadr for reading data\nggplot for plotting\nkableExtra for tables\nlibrary(pROC), library(regclass), and library(caret) for model diagnostics\n\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(readr)\nlibrary(pROC)\nlibrary(regclass)\nlibrary(caret)\n\n\n\nIn this practical, you will perform logistic regression analyses again using glm() and discuss model assumptions and diagnostics titanic data set.\n1. Read in the data from the “titanic.csv” file, which we also used for the previous practical.\n\n\n\n\nFit the following two logistic regression models and save them as fit1 and fit2:\n\n\nSurvived ~ Pclass\nSurvived ~ Age + Pclass*Sex"
  },
  {
    "objectID": "labs/lab6.html#loading-the-data",
    "href": "labs/lab6.html#loading-the-data",
    "title": "Lab 6",
    "section": "",
    "text": "In this practical, you will perform logistic regression analyses again using glm() and discuss model assumptions and diagnostics titanic data set.\n1. Read in the data from the “titanic.csv” file, which we also used for the previous practical."
  },
  {
    "objectID": "labs/lab6.html#logistic-regression",
    "href": "labs/lab6.html#logistic-regression",
    "title": "Lab 6",
    "section": "",
    "text": "Fit the following two logistic regression models and save them as fit1 and fit2:\n\n\nSurvived ~ Pclass\nSurvived ~ Age + Pclass*Sex"
  },
  {
    "objectID": "labs/lab6.html#binary-dependent-variable",
    "href": "labs/lab6.html#binary-dependent-variable",
    "title": "Lab 6",
    "section": "Binary dependent variable",
    "text": "Binary dependent variable\nThe first outcome in a logistic regression is that the outcome should be binary and therefore follow a binomial distribution. This is easy to check: you just need to be sure that the outcome can only take one of two responses. You can plot the responses of the outcome variable to visually check this if you want. In our case, the possible outcomes are:\n\nSurvived (coded 1)\nDid not survive (coded 0)\n\n\nVisualise the responses of the outcome variable Survived using ggplot()."
  },
  {
    "objectID": "labs/lab6.html#balanced-outcomes",
    "href": "labs/lab6.html#balanced-outcomes",
    "title": "Lab 6",
    "section": "Balanced outcomes",
    "text": "Balanced outcomes\nIf you are using logistic regression to make predictions/classifications then the accuracy will be affected by imbalance in the outcome classes. Notice that in the plot you just made there are more people who did not survive than who did survive. A possible consequence is reduced accuracy in classification of survivors.\nA certain amount of imbalance is expected and can be handled well by the model in most cases. The effects of this imbalance is context-dependent. Some solutions to serious class imbalance are down-sampling or weighting the outcomes to balance the importance placed on the outcomes by the model."
  },
  {
    "objectID": "labs/lab6.html#sufficiently-large-sample-size",
    "href": "labs/lab6.html#sufficiently-large-sample-size",
    "title": "Lab 6",
    "section": "Sufficiently large sample size",
    "text": "Sufficiently large sample size\nSample size in logistic regression is a complex issue, but some suggest that it is ideal to have 10 cases per candidate predictor in your model. The minimum number of cases to include is \\(N = \\frac{10*k} {p}\\), where \\(k\\) is the number of predictors and \\(p\\) is the smallest proportion of negative or positive cases in the population.\n\nCalculate the minimum number of positive cases needed in the model fit1."
  },
  {
    "objectID": "labs/lab6.html#predictor-matrix-is-full-rank",
    "href": "labs/lab6.html#predictor-matrix-is-full-rank",
    "title": "Lab 6",
    "section": "Predictor matrix is full-rank",
    "text": "Predictor matrix is full-rank\nYou learned about this assumption in the linear regression practicals, but to remind you:\n\nthere need to be more observations than predictors (n &gt; P)\nthere should be no multicollinearity among the linear predictors\n\n\nCheck that there is no multicollinearity in the logistic model."
  },
  {
    "objectID": "labs/lab6.html#continuous-predictors-are-linearly-related-to-the-logitpi",
    "href": "labs/lab6.html#continuous-predictors-are-linearly-related-to-the-logitpi",
    "title": "Lab 6",
    "section": "Continuous predictors are linearly related to the \\(logit(\\pi)\\)",
    "text": "Continuous predictors are linearly related to the \\(logit(\\pi)\\)\nLogistic regression models assume a linear relationship between predictor variables and the logit of the outcome variable. This assumption is mainly concerned with continuous predictors. Since we only have one continuous predictor (Age) we can plot the relationship between Age and the logit of Survived.\n\nGet the predicted values of fit2 on the logit scale and bind them to the titanic data.\nPlot the relationship between Age and logit and interpret it.\nHow should we deal with variables that are not linearly related to the logit?"
  },
  {
    "objectID": "labs/lab6.html#no-influential-values-or-outliers",
    "href": "labs/lab6.html#no-influential-values-or-outliers",
    "title": "Lab 6",
    "section": "No influential values or outliers",
    "text": "No influential values or outliers\nInfluential values are extreme individual data points that can affect the fit of the logistic regression model. They can be visualised using Cook’s distance and the Residuals vs Leverage plot.\n\nUse the plot() function to visualise the outliers and influential points of fit2.\n\nHint: you need to specify the correct plot with the which argument. Check the lecture slides or search ??plot if you are unsure.\n\nAre there any influential cases in the Leverage vs Residuals plot? If so, what would you do?"
  },
  {
    "objectID": "labs/lab6.html#differences-to-linear-regressoin",
    "href": "labs/lab6.html#differences-to-linear-regressoin",
    "title": "Lab 6",
    "section": "Differences to linear regressoin",
    "text": "Differences to linear regressoin\nLastly, it is important to note that the assumptions of a linear regression do not all map to logistic regression. In logistic regression, we do not need:\n\nconstant, finite error variance\nnormally distributed errors\n\nHowever, deviance residuals are useful for determining if the individual points are not fit well by the model.\nHint: you can use some of the code from the lecture for the next few questions.\n\nUse the resid() function to get the deviance residuals for fit2.\nCompute the predicted logit values for the model.\nPlot the deviance residuals.\n\nPearson residuals can also be useful in logistic regression. They measure deviations between the observed and fit1ted values. Pearson residuals are easier to plot than deviance residuals as the plot() function can be used.\n\nPlot the pearson residuals for the model."
  },
  {
    "objectID": "labs/lab6.html#confusion-matrix",
    "href": "labs/lab6.html#confusion-matrix",
    "title": "Lab 6",
    "section": "Confusion matrix",
    "text": "Confusion matrix\nYou can read about the confusion matrix on this Wikipedia page. This section tells you how to get some useful metrics from the confusion matrix to evaluate model performance.\n\nCreate two confusion matrices (one each for each model) using the classifications from the previous question. You can use the table() function, providing the modeled outcome as the true parameter and the classifications as the pred parameter.\nBased on the confusion matrices, which model do you think makes better predictions?\nCalculate the accuracy, sensitivity, and specificity, false positive rate, positive and negative predictive values from the confusion matrix of the model that makes the best predictions.\nExplain what the difference metrics mean in substantive terms?\nWhat does it mean for a model to have such low specificity, but high sensitivity?\n\nThe confusionMatrix() function from the caret package can do a lot of this for us. The function takes three arguments:\n\ndata - a vector of predicted classes (in factor form)\nreference - a vector of true classes (in factor from)\npositive - a character string indicating the ‘positive’ outcome. If not specified, the confusion matrix assumes that the first specified category is the positive outcome.\n\nYou can type ??confusionMatrix into the console to learn more."
  },
  {
    "objectID": "labs/lab6_answers.html",
    "href": "labs/lab6_answers.html",
    "title": "Lab 6",
    "section": "",
    "text": "We will use the following packages in this practical:\n\ndplyr for manipulation\nmagrittr for piping\nreadr for reading data\nggplot for plotting\nkableExtra for tables\nlibrary(pROC), library(regclass), and library(caret) for model diagnostics\n\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(readr)\nlibrary(pROC)\nlibrary(regclass)\nlibrary(caret)\n\n\n\nIn this practical, you will perform logistic regression analyses again using glm() and discuss model assumptions and diagnostics titanic data set.\n1. Read in the data from the “titanic.csv” file, which we also used for the previous practical.\n\n# Load in the data\ntitanic &lt;- read_csv(\"titanic.csv\") %&gt;% \n  mutate(Survived = as.factor(Survived),\n         Sex = as.factor(Sex),\n         Pclass = as.factor(Pclass))\n\nRows: 891 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Sex\ndbl (3): Survived, Pclass, Age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(titanic)\n\ntibble [891 × 4] (S3: tbl_df/tbl/data.frame)\n $ Survived: Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 1 1 1 2 2 ...\n $ Pclass  : Factor w/ 3 levels \"1\",\"2\",\"3\": 3 1 3 1 3 3 1 3 3 2 ...\n $ Age     : num [1:891] 22 38 26 35 35 ...\n $ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 2 1 1 ...\n\n#I use `readr::read_csv` to import the titanic training dataset, piping the input through `mutate_if` functions to correct the class. *\n\n#As a reminder, the variables are:*\n#`Survived` - passenger's survival status where 0 indicates did not survive, 1 indicats survived*\n#`Pclass` - 1st, 2nd, and 3rd class tickets*\n#`Age` - passenger age in years*\n#`Sex` - passenger sex as male or female*\n\n\n\n\n\nFit the following two logistic regression models and save them as fit1 and fit2:\n\n\nSurvived ~ Pclass\nSurvived ~ Age + Pclass*Sex\n\n\nfit1 &lt;- glm(Survived ~ Pclass, \n            family = binomial, \n            data = titanic)\n\nfit2 &lt;- glm(Survived ~ Age + Sex*Pclass, \n            family = binomial, \n            data = titanic)"
  },
  {
    "objectID": "labs/lab6_answers.html#loading-the-data",
    "href": "labs/lab6_answers.html#loading-the-data",
    "title": "Lab 6",
    "section": "",
    "text": "In this practical, you will perform logistic regression analyses again using glm() and discuss model assumptions and diagnostics titanic data set.\n1. Read in the data from the “titanic.csv” file, which we also used for the previous practical.\n\n# Load in the data\ntitanic &lt;- read_csv(\"titanic.csv\") %&gt;% \n  mutate(Survived = as.factor(Survived),\n         Sex = as.factor(Sex),\n         Pclass = as.factor(Pclass))\n\nRows: 891 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Sex\ndbl (3): Survived, Pclass, Age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(titanic)\n\ntibble [891 × 4] (S3: tbl_df/tbl/data.frame)\n $ Survived: Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 1 1 1 2 2 ...\n $ Pclass  : Factor w/ 3 levels \"1\",\"2\",\"3\": 3 1 3 1 3 3 1 3 3 2 ...\n $ Age     : num [1:891] 22 38 26 35 35 ...\n $ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 2 1 1 ...\n\n#I use `readr::read_csv` to import the titanic training dataset, piping the input through `mutate_if` functions to correct the class. *\n\n#As a reminder, the variables are:*\n#`Survived` - passenger's survival status where 0 indicates did not survive, 1 indicats survived*\n#`Pclass` - 1st, 2nd, and 3rd class tickets*\n#`Age` - passenger age in years*\n#`Sex` - passenger sex as male or female*"
  },
  {
    "objectID": "labs/lab6_answers.html#logistic-regression",
    "href": "labs/lab6_answers.html#logistic-regression",
    "title": "Lab 6",
    "section": "",
    "text": "Fit the following two logistic regression models and save them as fit1 and fit2:\n\n\nSurvived ~ Pclass\nSurvived ~ Age + Pclass*Sex\n\n\nfit1 &lt;- glm(Survived ~ Pclass, \n            family = binomial, \n            data = titanic)\n\nfit2 &lt;- glm(Survived ~ Age + Sex*Pclass, \n            family = binomial, \n            data = titanic)"
  },
  {
    "objectID": "labs/lab6_answers.html#binary-dependent-variable",
    "href": "labs/lab6_answers.html#binary-dependent-variable",
    "title": "Lab 6",
    "section": "Binary dependent variable",
    "text": "Binary dependent variable\nThe first outcome in a logistic regression is that the outcome should be binary and therefore follow a binomial distribution. This is easy to check: you just need to be sure that the outcome can only take one of two responses. You can plot the responses of the outcome variable to visually check this if you want. In our case, the possible outcomes are:\n\nSurvived (coded 1)\nDid not survive (coded 0)\n\n\nVisualise the responses of the outcome variable Survived using ggplot().\n\n\ntitanic %&gt;% \n  ggplot(aes(x = Survived, fill = Survived)) +\n  geom_bar() +\n  labs(x = \"Survival\",\n       y = \"Count\",\n       title = \"Distribution of the outcome variable\") +\n  theme_bw()\n\n\n\n\n\n\n\n# You can see that there are indeed only two outcomes for `Survived`, so our outcome follows a binomial distribution."
  },
  {
    "objectID": "labs/lab6_answers.html#balanced-outcomes",
    "href": "labs/lab6_answers.html#balanced-outcomes",
    "title": "Lab 6",
    "section": "Balanced outcomes",
    "text": "Balanced outcomes\nIf you are using logistic regression to make predictions/classifications then the accuracy will be affected by imbalance in the outcome classes. Notice that in the plot you just made there are more people who did not survive than who did survive. A possible consequence is reduced accuracy in classification of survivors.\nA certain amount of imbalance is expected and can be handled well by the model in most cases. The effects of this imbalance is context-dependent. Some solutions to serious class imbalance are down-sampling or weighting the outcomes to balance the importance placed on the outcomes by the model."
  },
  {
    "objectID": "labs/lab6_answers.html#sufficiently-large-sample-size",
    "href": "labs/lab6_answers.html#sufficiently-large-sample-size",
    "title": "Lab 6",
    "section": "Sufficiently large sample size",
    "text": "Sufficiently large sample size\nSample size in logistic regression is a complex issue, but some suggest that it is ideal to have 10 cases per candidate predictor in your model. The minimum number of cases to include is \\(N = \\frac{10*k} {p}\\), where \\(k\\) is the number of predictors and \\(p\\) is the smallest proportion of negative or positive cases in the population.\n\nCalculate the minimum number of positive cases needed in the model fit1.\n\n\n#First we need to get the proportion of people that survived in our sample, which is 0.38*\n\ntitanic %&gt;% \n  count(Survived) %&gt;% \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  Survived     n  prop\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 0          549 0.616\n2 1          342 0.384\n\n#Now we can plug this into our formula to get the minimum number of positive cases. \nssize_cal &lt;- function(k, p){\n  round((10*k)/p)\n}\n\nssize_cal(2, 0.38)\n\n[1] 53\n\n#We have many more than this in our data so the sample size is large enough.*"
  },
  {
    "objectID": "labs/lab6_answers.html#predictor-matrix-is-full-rank",
    "href": "labs/lab6_answers.html#predictor-matrix-is-full-rank",
    "title": "Lab 6",
    "section": "Predictor matrix is full-rank",
    "text": "Predictor matrix is full-rank\nYou learned about this assumption in the linear regression practicals, but to remind you:\n\nthere need to be more observations than predictors (n &gt; P)\nthere should be no multicollinearity among the linear predictors\n\n\nCheck that there is no multicollinearity in the logistic model.\n\n\n#VIF(fit1)\nVIF(fit2)\n\n                GVIF Df GVIF^(1/(2*Df))\nAge         1.236805  1        1.112117\nSex        10.776569  1        3.282769\nPclass     28.991163  2        2.320419\nSex:Pclass 42.044233  2        2.546400\n\n# Like with linear regression we can use the VIF. A VIV &gt; 10 indicates high multicollinearity. Remember that for continuous variables we should inspect the \"GVIF\" column. For categorical predictors we should check the \"GVIF^(1/(2*Df))\" column.\n\n# In model 1, the VIF cannot be determined since there is only a single predictor."
  },
  {
    "objectID": "labs/lab6_answers.html#continuous-predictors-are-linearly-related-to-the-logitpi",
    "href": "labs/lab6_answers.html#continuous-predictors-are-linearly-related-to-the-logitpi",
    "title": "Lab 6",
    "section": "Continuous predictors are linearly related to the \\(logit(\\pi)\\)",
    "text": "Continuous predictors are linearly related to the \\(logit(\\pi)\\)\nLogistic regression models assume a linear relationship between predictor variables and the logit of the outcome variable. This assumption is mainly concerned with continuous predictors. Since we only have one continuous predictor (Age) we can plot the relationship between Age and the logit of Survived.\n\nGet the predicted values of fit2 on the logit scale and bind them to the titanic data.\n\n\n# We do this using the `predict()` function, but specifying `type = \"link\"` this time. \n\ntitanic$logit &lt;- predict(fit2, type = \"link\")\n\n\nPlot the relationship between Age and logit and interpret it.\n\n\ntitanic %&gt;% \nggplot(aes(Age, logit))+\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(method = \"glm\") + \n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Age does appear to be negatively linearly related to the predicted logit values.\n\n\nHow should we deal with variables that are not linearly related to the logit?\n\n\n# This differs per situation. One solution can be to try to apply transformations to the variables."
  },
  {
    "objectID": "labs/lab6_answers.html#no-influential-values-or-outliers",
    "href": "labs/lab6_answers.html#no-influential-values-or-outliers",
    "title": "Lab 6",
    "section": "No influential values or outliers",
    "text": "No influential values or outliers\nInfluential values are extreme individual data points that can affect the fit of the logistic regression model. They can be visualised using Cook’s distance and the Residuals vs Leverage plot.\n\nUse the plot() function to visualise the outliers and influential points of fit2.\n\nHint: you need to specify the correct plot with the which argument. Check the lecture slides or search ??plot if you are unsure.\n\n# There are two relevant plots to check for influential values. The first is Cook's distance plot, which shows the top 3 largest values. Note that not all outliers are influential cases, so we should also inspect the Residuals vs Leverage plot, which shows actual influential cases.\n\n# You can get both of these plots by specifying `which = c(4, 5)` in the `plot()` function.\n\nplot(fit2, which = c(4, 5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre there any influential cases in the Leverage vs Residuals plot? If so, what would you do?\n\n\n# Leverage is the extent that the model coefficients will change if a particular observation is removed from the dataset. Points that fall outside of the red dashed line (Cook's distance) are influential.*\n\n# There are no values which fall outside of the red dashed lines.* \n\n# If there are influential observations, you can remove them, replace them with a more realistic value, or keep them as they are and make note of it when reporting results.*"
  },
  {
    "objectID": "labs/lab6_answers.html#differences-to-linear-regressoin",
    "href": "labs/lab6_answers.html#differences-to-linear-regressoin",
    "title": "Lab 6",
    "section": "Differences to linear regressoin",
    "text": "Differences to linear regressoin\nLastly, it is important to note that the assumptions of a linear regression do not all map to logistic regression. In logistic regression, we do not need:\n\nconstant, finite error variance\nnormally distributed errors\n\nHowever, deviance residuals are useful for determining if the individual points are not fit well by the model.\nHint: you can use some of the code from the lecture for the next few questions.\n\nUse the resid() function to get the deviance residuals for fit2.\n\n\ndr &lt;- resid(fit2, type = \"deviance\")\n\n\nCompute the predicted logit values for the model.\n\n\neta &lt;- predict(fit2, type = \"link\")\n\n\nPlot the deviance residuals.\n\n\n# The first step is to bind the deviance residuals to the logit values.\n\ndr_data &lt;- data.frame(residuals = dr, \n                      eta = rep(eta, 3))\n\nWarning in data.frame(residuals = dr, eta = rep(eta, 3)): row names were found\nfrom a short variable and have been discarded\n\n# Now we can plot the data with the residuals on the y-axis, and the logit values on the x-axis.* \n\nggplot(dr_data, aes(x = eta, y = residuals)) + \n  geom_point(alpha = 0.35) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Deviance residuals\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nPearson residuals can also be useful in logistic regression. They measure deviations between the observed and fit1ted values. Pearson residuals are easier to plot than deviance residuals as the plot() function can be used.\n\nPlot the pearson residuals for the model.\n\n\nplot(fit2, which = 1)"
  },
  {
    "objectID": "labs/lab6_answers.html#confusion-matrix",
    "href": "labs/lab6_answers.html#confusion-matrix",
    "title": "Lab 6",
    "section": "Confusion matrix",
    "text": "Confusion matrix\nYou can read about the confusion matrix on this Wikipedia page. This section tells you how to get some useful metrics from the confusion matrix to evaluate model performance.\n\nCreate two confusion matrices (one each for each model) using the classifications from the previous question. You can use the table() function, providing the modeled outcome as the true parameter and the classifications as the pred parameter.\n\n\n# The confusion matrix can be interpreted as follows:\n\n# True positives (bottom right) - correctly predicting people that survived\n# True negatives (top left) - correctly predicting people that did not survive\n# False positives (bottom left) - predicted people survived, when they did not\n# False negatives (top right) - predicting people did not survived, but they did\n\ncm1 &lt;- table(pred = pred1, true = titanic$Survived)\ncm2 &lt;- table(pred = pred2, true = titanic$Survived)\n\ncm1\n\n    true\npred   0   1\n   0 469 206\n   1  80 136\n\ncm2\n\n    true\npred   0   1\n   0 505 143\n   1  44 199\n\n\n\n# Note: the structure of the confusion matrix depends on the order in which you supply the outcome (i.e., if 0 and 1 were swapped, or if the predicted and true values are switched in rows and columns. \n\n# A third confusion matrix is given in which the order is changed. Always make sure that you read the confusion matrix carefully, so that you notice deviating structures. \n\ntable(true = titanic$Survived, pred = pred2)\n\n    pred\ntrue   0   1\n   0 505  44\n   1 143 199\n\n\n\nBased on the confusion matrices, which model do you think makes better predictions?\n\n\n# The second model makes more correct predictions according to the confusion matrix:\n\n# There are 505 correct true negative predictions, and 199 correct true positive predictions from model 2.\n# There are 469 correct true negative predictions and 136 true positive predictions from model 1 by comparison.\n\n# The first model makes more incorrect predictions too:*\n\n# There are 143 false negative predictions and 44 false positive predictions from model 2\n# There are 206 false negative predictions and 80 false positive predictions from model 1\n\n\nCalculate the accuracy, sensitivity, and specificity, false positive rate, positive and negative predictive values from the confusion matrix of the model that makes the best predictions.\n\n\n# First you need to extract the true negative, false negative, true positive, and false positive values from the confusion matrix.\nTN &lt;- cm2[1, 1]\nFN &lt;- cm2[1, 2]\nTP &lt;- cm2[2, 2]\nFP &lt;- cm2[2, 1]\n\n# Then you can use these values to calculate the metric asked for.\ntibble(\n  ACCURACY = (TP + TN) / sum(cm2),\n  SENSITIVITY = TP / (TP + FN),\n  SPECIFICITY = TN / (TN + FP),\n  FPR = FP / (TN + FP),\n  PPV = TP / (TP + FP),\n  NPV = TN / (TN + FN)\n  )\n\n# A tibble: 1 × 6\n  ACCURACY SENSITIVITY SPECIFICITY    FPR   PPV   NPV\n     &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.790       0.582       0.920 0.0801 0.819 0.779\n\n\n\nExplain what the difference metrics mean in substantive terms?\n\n\n# Model accuracy is 0.79, meaning that 79% are correctly classified.\n\n# Model sensitivity is 0.58, meaning that if the passenger did survive, there is a 58% chance the model will detect this.\n\n# Model specificity is 0.92, meaning that if the passenger did not survive is an 92% chance the model will detect this.\n\n# Model FPR is 0.08, meaning that if a passenger in reality did not survive, there is a 8% chance that the model predicts this passenger as surviving.\n\n# Model PPV is 0.82, meaning that if a passenger is predicted as surviving, there is a 82% chance that this passenger indeed survived.\n\n# Model NPV is 0.78, meaning that if the passenger predicted as not surviving, there is a 78% chance that this passenger indeed did not survive.\n\n\nWhat does it mean for a model to have such low specificity, but high sensitivity?\n\n\n# Sensitivity and specificity are inversely proportioned. This means that as one increases, the other will decrease.\n\n# In our example we have moderate sensitivity, and very high specificity. High specificity means that there are few passengers predicted as not surviving when in reality they did survive. A moderate sensitivity means that relatively more passengers were predicted as surviving when in reality they did not survive. \n\nThe confusionMatrix() function from the caret package can do a lot of this for us. The function takes three arguments:\n\ndata - a vector of predicted classes (in factor form)\nreference - a vector of true classes (in factor from)\npositive - a character string indicating the ‘positive’ outcome. If not specified, the confusion matrix assumes that the first specified category is the positive outcome.\n\nYou can type ??confusionMatrix into the console to learn more.\n\nconfusionMatrix(as.factor(pred2), \n                reference = titanic$Survived, \n                positive = \"1\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 505 143\n         1  44 199\n                                          \n               Accuracy : 0.7901          \n                 95% CI : (0.7619, 0.8164)\n    No Information Rate : 0.6162          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.5307          \n                                          \n Mcnemar's Test P-Value : 7.696e-13       \n                                          \n            Sensitivity : 0.5819          \n            Specificity : 0.9199          \n         Pos Pred Value : 0.8189          \n         Neg Pred Value : 0.7793          \n             Prevalence : 0.3838          \n         Detection Rate : 0.2233          \n   Detection Prevalence : 0.2727          \n      Balanced Accuracy : 0.7509          \n                                          \n       'Positive' Class : 1"
  }
]