{
  "hash": "2d4d6f0970859dddd4322ac2c5b92f7f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 3\"\noutput-file: \"lab3_answers.html\"\n#output-file: \"lab3.html\"\nparams:\n  answers: true\n---\n\n\n\n\n\n\n\n\n\n\n# Part 1: Repeat from last week\n\nWe will use the following packages in this practical:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(gridExtra)\n```\n:::\n\n\nWe will use the same data that we used last week to perform a simple linear regression, the Iris dataset. But now, we will extend on this simple model with multiple variables.\n\nIn order to do this, we first need to load the data again and run the simple model where Sepal length is predicted by Petal width.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- iris # load the data\nhead(iris)   # inspect the data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# specify model\nmodel1 <- lm(Sepal.Length ~ Petal.Width, \n             data = data)\n\n# ask for summary\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Width, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38822 -0.29358 -0.04393  0.26429  1.34521 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.77763    0.07293   65.51   <2e-16 ***\nPetal.Width  0.88858    0.05137   17.30   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.478 on 148 degrees of freedom\nMultiple R-squared:  0.669,\tAdjusted R-squared:  0.6668 \nF-statistic: 299.2 on 1 and 148 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n# Part 2: Multiple linear regression\n\nYou can add additional predictors to a model. This can improve the fit and the predictions. When multiple predictors are used in a regression model, it's called a Multiple linear regression. You specify this model as `outcome_variable ~ predictor_1 + predictor_2 + ... + predictor_n`.\n\n1.  **Add Petal length as a second predictor to the model specified as `model1` and store this under the name `model2`, and supply summary statistics. Again, give a substantive interpretation of the coefficients and the model.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify additional predictors\nmodel2 <- lm(Sepal.Length ~ Petal.Width + Petal.Length, \n             data = data)\n\n# Ask for summary statistics again\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Width + Petal.Length, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.18534 -0.29838 -0.02763  0.28925  1.02320 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   4.19058    0.09705  43.181  < 2e-16 ***\nPetal.Width  -0.31955    0.16045  -1.992   0.0483 *  \nPetal.Length  0.54178    0.06928   7.820 9.41e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4031 on 147 degrees of freedom\nMultiple R-squared:  0.7663,\tAdjusted R-squared:  0.7631 \nF-statistic:   241 on 2 and 147 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# When comparing the coefficients of model 2 with the coefficients of model 1, we can see that adding a predictor can change the coefficients of other predictors as well (it is a new model after all). In this example, it is notable that the coefficient for petal width has become a negative number, while it was positive in model 1.\n```\n:::\n\n\n## Categorical predictors\n\nUp to here, we only included continuous predictors in our models. We will now include a categorical predictor in the model as well.\n\nWhen a categorical predictor is added, this predictor is split in several contrasts (or dummies), where each group is compared to a reference group. In our example Iris data, the variable 'Species' is a categorical variable that indicate the species of flower. This variable can be added as example for a categorical predictor. Contrasts, and thus the dummy coding, can be inspected through `contrasts()`.\n\n2.  **Add species as a predictor to the model specified as `model2`, store it under the name `model3` and interpret the categorical coefficients of this new model.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 3rd model with categorical predictor\nmodel3 <- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Species,\n             data = data)\n\n# Ask for summary data\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Species, \n    data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.82156 -0.20530  0.00638  0.22645  0.74999 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        2.39039    0.26227   9.114 5.94e-16 ***\nSepal.Width        0.43222    0.08139   5.310 4.03e-07 ***\nPetal.Length       0.77563    0.06425  12.073  < 2e-16 ***\nSpeciesversicolor -0.95581    0.21520  -4.442 1.76e-05 ***\nSpeciesvirginica  -1.39410    0.28566  -4.880 2.76e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3103 on 145 degrees of freedom\nMultiple R-squared:  0.8633,\tAdjusted R-squared:  0.8595 \nF-statistic: 228.9 on 4 and 145 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# In the output, we see that 'Species' has multiple rows of output, and that one species (Setosa) does not seem to show. Setosa is the reference group. The other two lines are those respecitve groups compared to the setosa group. This means that that the predicted sepal length of a versicolor would be .9558 lower than the predicted value of a setosas with the same values on the other variables.\n```\n:::\n\n\n# Part 3: Model comparison\n\nNow you have created multiple models, you can compare how well these models function (compare the model fit). There are multiple ways of testing the model fit and to compare models, as explained in the lecture and the reading material. In this practical, we use the following:\n\n-   AIC (use the function `AIC()` on the model object)\n-   BIC (use the function `BIC()` on the model object)\n-   MSE (use `MSE()` of the `MLmetrics` package, or calculate by transforming the `model$residuals`)\n-   Deviance test (use `anova()` to compare 2 models)\n\n3.  **Compare the fit of the model specified under question 5 and the model specified under question 8. Use all four fit comparison methods listed above. Interpret the fit statistics you obtain/tests you use to compare the fit.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAICvalues <- rbind(AIC(model1), AIC(model2))\nBICvalues <- rbind(BIC(model1), BIC(model2))\nMSEvalues <- rbind(mean(model1$residuals^2), \n                    mean(model2$residuals^2))\n\nmodelfitvalues <- cbind(AICvalues, BICvalues, MSEvalues)\nrownames(modelfitvalues) <- c(\"model1\", \"model2\")\ncolnames(modelfitvalues) <- c(\"AIC\", \"BIC\", \"MSE\")\nmodelfitvalues \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            AIC      BIC       MSE\nmodel1 208.2215 217.2534 0.2254326\nmodel2 158.0468 170.0894 0.1592046\n```\n\n\n:::\n\n```{.r .cell-code}\n# We see that the second AIC is lower, and thus this model has a better fit-complexity trade-off. The BIC has the same conclusion as the AIC in this case. The MSE of the second model is lower, and therefore indicates less error and a better fit.\n\n# R2 difference test (deviance)\nanova(model1, model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: Sepal.Length ~ Petal.Width\nModel 2: Sepal.Length ~ Petal.Width + Petal.Length\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1    148 33.815                                  \n2    147 23.881  1    9.9342 61.151 9.414e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# The residual sum of squares is significantly lower for model 2, indicating a better fit for this model\n```\n:::\n\n\n# Part 4: Residuals: observed vs. predicted\n\nWhen fitting a regression line, the predicted values have some error in comparison to the observed values. The sum of the squared values of these errors is the sum of squares. A regression analysis finds the line such that the lowest sum of squares possible is obtained.\n\nThe image below shows how the predicted (on the blue regression line) and observed values (black dots) differ and how the predicted values have some error (red vertical lines).\n\n![](errorterms.PNG)\n\nWhen having multiple predictors, it becomes harder or impossible to make such a plot as above (you need a plot with more dimensions). You can, however, still plot the observed values against the predicted values and infer the error terms from there.\n\n4.  **Create a dataset of predicted values for model 1 by taking the outcome variable `Sepal.Length` and the `fitted.values` from the model.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredvals1           <- cbind(data$Sepal.Length, model1$fitted.values)\ncolnames(predvals1) <- c(\"observed\", \"predicted\")\npredvals1           <- as.data.frame(predvals1)\n```\n:::\n\n\n5.  **Create an observed vs. predicted plot for model 1 (the red vertial lines are no must).**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobspred1 <- ggplot(data = predvals1, aes(x = observed, y = predicted)) +\n  geom_segment(aes(xend = observed, yend = observed), col = \"red\") +\n  geom_abline(slope = 1, intercept = 0, col = \"blue\") +\n  geom_point() +\n  ggtitle(\"Observed vs. Predicted - model 1\")\n```\n:::\n\n\n6.  **Create a dataset of predicted values and create a plot for model 2.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredvals2 <- cbind(data$Sepal.Length, model2$fitted.values)\ncolnames(predvals2) <- c(\"observed\", \"predicted\")\npredvals2 <- as.data.frame(predvals2)\n\nobspred2 <- ggplot(data = predvals2, aes(x = observed, y = predicted)) +\n  geom_segment(aes(xend = observed, yend = observed), col = \"red\") +\n  geom_abline(slope = 1, intercept = 0, col = \"blue\") +\n  geom_point() +\n  ggtitle(\"Observed vs. Predicted - model 2\")\n```\n:::\n\n\n7.  **Compare the two plots and discuss the fit of the models based on what you see in the plots. You can combine them in one figure using the `grid.arrange()` function.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(obspred1, obspred2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](lab3_answers_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Above, the observed vs. predicted plots for both model 1 (1 predictor) and model 2 (an additional predictor) are shown. In the second plot, it can be seen that all the red lines are shorter, indicating less error, a lower sum of squares, and thus a better fit.\n```\n:::\n\n\n## Calculating new predicted values\n\nA regression model can be used to predict values for new cases that were not used to built the model. The regression equation always consists of coefficients ($\\beta$s) and observed variables ($X$):\n\n<br>\n\n$$\\hat{y} = \\beta_0 + \\beta_1 * X_{a}* + \\beta_2 * X_b +  \\ldots  + \\beta_n * X_n$$",
    "supporting": [
      "lab3_answers_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}